{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rXC93PvZHALw"
   },
   "source": [
    "# Import e path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JBzM4-qJKiU8",
    "outputId": "ea57b21d-454c-42fa-8455-6fd55c929352"
   },
   "outputs": [],
   "source": [
    "# !pip install einops\n",
    "# !pip install vit_pytorch\n",
    "# !pip install tinyimagenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "bBKm4O3pn19s"
   },
   "outputs": [],
   "source": [
    "models_save_path        = \"./model\"\n",
    "results_save_path_agent = \"./result\"\n",
    "dataset_path            = \"./dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yt6SLbwUnu6r",
    "outputId": "ccf85f74-69f1-490e-a33f-50c95b0d5704"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "jX7uYCACg2j5"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Libraries for data handling\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Libraries for image manipulation and machine learning\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "# Libraries for data handling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Libraries for image manipulation and machine learning\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional\n",
    "import torch.optim as optim\n",
    "\n",
    "# Library to load in tinyimagenet\n",
    "from tinyimagenet import TinyImageNet\n",
    "from pathlib import Path\n",
    "\n",
    "!pip install scikit-learn\n",
    "\n",
    "# Libraries for model evaluation metrics\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "# Libraries for tensor manipulation\n",
    "from einops import rearrange\n",
    "from einops.layers.torch import Rearrange\n",
    "\n",
    "# Libraries for simulation environments (gym)\n",
    "import gym\n",
    "\n",
    "# Libraries for data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Other common libraries\n",
    "from collections import namedtuple\n",
    "import math\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "\n",
    "from dqn_agent import *\n",
    "from train_test_agent import *\n",
    "from rl_env import *\n",
    "from vit import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xi1SBM-8TRqg"
   },
   "source": [
    "<h3> Seed and Device setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zIBVHD-TTU6u",
    "outputId": "b3cc1768-3efe-4d1e-f87f-1ee05db4f351"
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "qL0i8NnGpUPc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ng75uqlIgCvl"
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "diI87IeqHIE5"
   },
   "source": [
    "<h3> Dataset Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "XLxr6JMmgP0g"
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "img_size = 64\n",
    "# dataset_name = \"CIFAR10_BIG_\"\n",
    "dataset_name = \"TinyImageNet\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SWAh2lXxHQhL"
   },
   "source": [
    "## Train, validation and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TPPcrxFQHS-r",
    "outputId": "b9f10298-3e75-4872-c89d-0fc282b5dc1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset downloaded!\n",
      "trainloader created successfully.\n",
      "['n01443537', 'n01629819', 'n01641577', 'n01644900', 'n01698640', 'n01742172', 'n01768244', 'n01770393', 'n01774384', 'n01774750', 'n01784675', 'n01855672', 'n01882714', 'n01910747', 'n01917289', 'n01944390', 'n01945685', 'n01950731', 'n01983481', 'n01984695', 'n02002724', 'n02056570', 'n02058221', 'n02074367', 'n02085620', 'n02094433', 'n02099601', 'n02099712', 'n02106662', 'n02113799', 'n02123045', 'n02123394', 'n02124075', 'n02125311', 'n02129165', 'n02132136', 'n02165456', 'n02190166', 'n02206856', 'n02226429', 'n02231487', 'n02233338', 'n02236044', 'n02268443', 'n02279972', 'n02281406', 'n02321529', 'n02364673', 'n02395406', 'n02403003', 'n02410509', 'n02415577', 'n02423022', 'n02437312', 'n02480495', 'n02481823', 'n02486410', 'n02504458', 'n02509815', 'n02666196', 'n02669723', 'n02699494', 'n02730930', 'n02769748', 'n02788148', 'n02791270', 'n02793495', 'n02795169', 'n02802426', 'n02808440', 'n02814533', 'n02814860', 'n02815834', 'n02823428', 'n02837789', 'n02841315', 'n02843684', 'n02883205', 'n02892201', 'n02906734', 'n02909870', 'n02917067', 'n02927161', 'n02948072', 'n02950826', 'n02963159', 'n02977058', 'n02988304', 'n02999410', 'n03014705', 'n03026506', 'n03042490', 'n03085013', 'n03089624', 'n03100240', 'n03126707', 'n03160309', 'n03179701', 'n03201208', 'n03250847', 'n03255030', 'n03355925', 'n03388043', 'n03393912', 'n03400231', 'n03404251', 'n03424325', 'n03444034', 'n03447447', 'n03544143', 'n03584254', 'n03599486', 'n03617480', 'n03637318', 'n03649909', 'n03662601', 'n03670208', 'n03706229', 'n03733131', 'n03763968', 'n03770439', 'n03796401', 'n03804744', 'n03814639', 'n03837869', 'n03838899', 'n03854065', 'n03891332', 'n03902125', 'n03930313', 'n03937543', 'n03970156', 'n03976657', 'n03977966', 'n03980874', 'n03983396', 'n03992509', 'n04008634', 'n04023962', 'n04067472', 'n04070727', 'n04074963', 'n04099969', 'n04118538', 'n04133789', 'n04146614', 'n04149813', 'n04179913', 'n04251144', 'n04254777', 'n04259630', 'n04265275', 'n04275548', 'n04285008', 'n04311004', 'n04328186', 'n04356056', 'n04366367', 'n04371430', 'n04376876', 'n04398044', 'n04399382', 'n04417672', 'n04456115', 'n04465501', 'n04486054', 'n04487081', 'n04501370', 'n04507155', 'n04532106', 'n04532670', 'n04540053', 'n04560804', 'n04562935', 'n04596742', 'n04597913', 'n06596364', 'n07579787', 'n07583066', 'n07614500', 'n07615774', 'n07695742', 'n07711569', 'n07715103', 'n07720875', 'n07734744', 'n07747607', 'n07749582', 'n07753592', 'n07768694', 'n07871810', 'n07873807', 'n07875152', 'n07920052', 'n09193705', 'n09246464', 'n09256479', 'n09332890', 'n09428293', 'n12267677']\n"
     ]
    }
   ],
   "source": [
    "datasets = [\"tinyimagenet\", \"cifar10\"]\n",
    "use_subset = False\n",
    "subset_classes = 20\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(img_size, padding=8),\n",
    "    transforms.Resize(img_size),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=TinyImageNet.mean, std=TinyImageNet.std),\n",
    "])\n",
    "\n",
    "transform_validation = transforms.Compose([\n",
    "    transforms.Resize(img_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=TinyImageNet.mean, std=TinyImageNet.std),\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Prepare and load TinyImageNet dataset\n",
    "# trainset = TinyImageNet(Path(\"~/.torchvision/tinyimagenet/\"),split=\"train\",imagenet_idx=False, transform=transform_train)\n",
    "# validationset = TinyImageNet(Path(\"~/.torchvision/tinyimagenet/\"),split=\"val\",imagenet_idx=False, transform=transform_validation)\n",
    "\n",
    "# Prepare/download CIFAR10 dataset\n",
    "trainset = torchvision.datasets.CIFAR10(root=dataset_path, train=True, download=True, transform=transform_train)\n",
    "validationset = torchvision.datasets.CIFAR10(root=dataset_path, train=False, download=True, transform=transform_validation)\n",
    "\n",
    "print(\"Dataset downloaded!\")\n",
    "# Only select 20 classes from tinyimagenet.\n",
    "if use_subset:\n",
    "    print(\"Using subset of {} classes\".format(subset_classes))\n",
    "     # Select 20 random classes\n",
    "    selected_classes = list(range(subset_classes)) \n",
    "    class_to_idx = {cls: idx for idx, cls in enumerate(selected_classes)}\n",
    "\n",
    "\n",
    "    # Filter the dataset to include only the selected classes\n",
    "    train_subset_indices = [i for i, (_, label) in enumerate(validationset) if label in selected_classes]\n",
    "    val_subset = data.Subset(validationset, train_subset_indices)\n",
    "    val_subset_indices = [i for i, (_, label) in enumerate(trainset) if label in selected_classes]\n",
    "    train_subset = data.Subset(trainset, val_subset_indices)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_subset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "    print(\"trainloader created successfully.\")\n",
    "    dataset_size = len(val_subset)\n",
    "    validation_size = int(0.95 * dataset_size)\n",
    "    test_size = dataset_size - validation_size\n",
    "\n",
    "    val_subset, test_subset = data.random_split(val_subset, [validation_size, test_size])\n",
    "\n",
    "    validation_loader = torch.utils.data.DataLoader(val_subset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "    test_loader = torch.utils.data.DataLoader(test_subset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "else:\n",
    "    dataset_size = len(validationset)\n",
    "    validation_size = int(0.95 * dataset_size)\n",
    "    test_size = dataset_size - validation_size\n",
    "    validationset, testset = data.random_split(validationset, [validation_size, test_size])\n",
    "    train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "    validation_loader = torch.utils.data.DataLoader(validationset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "    test_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "# classes = trainset.classes\n",
    "classes = class_to_idx\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "950\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(len(val_subset.indices))\n",
    "print(len(train_subset.indices))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_4JC4EFqtfK5"
   },
   "source": [
    "# Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YL2DwKZ1Mdkr"
   },
   "source": [
    "### Functions for training and validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S9IYQ9yHAUwe"
   },
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "TaR2dDv2MQaV"
   },
   "outputs": [],
   "source": [
    "buffer_batch_size = 8\n",
    "buffer_size = 64\n",
    "\n",
    "gamma = 0.95\n",
    "\n",
    "eps_start = 1\n",
    "eps_end = 0.01\n",
    "eps = eps_start\n",
    "eps_decay = 20000\n",
    "\n",
    "lr = 0.01\n",
    "\n",
    "tau = 0.1\n",
    "update_every = 2\n",
    "\n",
    "get_reward_every = 10\n",
    "\n",
    "pretrained = False # Pretrained with CIFAR10 weights, that is.\n",
    "\n",
    "max_reward = 10\n",
    "alpha = 0.2 # Where alpha defines weight of loss reward, and 1-alpha defines weight of patch (time) reward\n",
    "# loss_weight = max_reward*(alpha)  # TODO THIS ONE TOO\n",
    "# time_weight = max_reward*(1-alpha) # TODO PLAY WITH THESE VALUES A LOT\n",
    "loss_weight = alpha\n",
    "time_weight = 1-alpha\n",
    "    \n",
    "# Input image to DQN agent's  Q-network\n",
    "# for CIFAR, lowres=16, fullres=32\n",
    "# For TinyImageNet, halfres = 32, fullres = 64\n",
    "dqn_img_w = 32\n",
    "dqn_input_channels = 3\n",
    "dqn_input_size = dqn_img_w*dqn_img_w*dqn_input_channels # input to DQN (mlp type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "TaR2dDv2MQaV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    }
   ],
   "source": [
    "# This is the number of patches along the width/height of the square image.\n",
    "# TODO refactor...img_size is defined WAY up in the notebook, right before dataset loader initialization\n",
    "patch_width = 8\n",
    "# patch_size = int(img_size/patch_width)\n",
    "patch_size = patch_width # This is what you get when you work with someone else's code and don't want to rewrite everything.\n",
    "\n",
    "\n",
    "total_patches = int((img_size/patch_width)**2)\n",
    "print(total_patches)\n",
    "n_patch_selected = int(total_patches*(40/64)) # From the paper\n",
    "\n",
    "\n",
    "att_dim = 128\n",
    "\n",
    "epochs = 20\n",
    "learning_rate = 0.001\n",
    "\n",
    "ViTnet = SimpleAgentViT(\n",
    "    image_size = img_size,\n",
    "    patch_size = patch_size,\n",
    "    num_classes = len(classes),\n",
    "    dim = att_dim,\n",
    "    depth = 6,\n",
    "    heads = 16,\n",
    "    mlp_dim = 512\n",
    ")\n",
    "\n",
    "# Sposta il modello sulla GPU (se disponibile)\n",
    "ViTnet.to(device)\n",
    "\n",
    "# definiamo l'ottimizzatore\n",
    "optimizer = optim.Adam(ViTnet.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "_ernM9pqoxbd"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#env = ViTEnv(ViTnet, total_patches, optimizer, loss_weight, time_weight, device, n_patch_selected)\n",
    "env = ViTEnv(ViTnet, total_patches, optimizer, loss_weight, time_weight, device, n_patch_selected, total_epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "iRn2Tplb90tO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNet created! Value of pretrained: False\n",
      "ConvNet created! Value of pretrained: False\n"
     ]
    }
   ],
   "source": [
    "model = TrainingTestingAgent(epochs = epochs,\n",
    "                             model = ViTnet,\n",
    "                             get_reward_every = get_reward_every,\n",
    "                             buffer_batch_size = buffer_batch_size,\n",
    "                             batch_size = batch_size,\n",
    "                             env = env,\n",
    "                             att_dim = att_dim,\n",
    "                             n_patches = total_patches,\n",
    "                             buffer_size = buffer_size,\n",
    "                             gamma = gamma,\n",
    "                             tau = tau,\n",
    "                             update_every = update_every,\n",
    "                             lr = lr,\n",
    "                             eps_end = eps_end,\n",
    "                             eps_start = eps_start,\n",
    "                             eps_decay = eps_decay,\n",
    "                             train_loader = train_loader,\n",
    "                             validation_loader = validation_loader,\n",
    "                             device = device,\n",
    "                             dqn_input_size=dqn_input_size,\n",
    "                             pretrained=pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "x7P_6HzWGn8G"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNet created! Value of pretrained: False\n",
      "ConvNet created! Value of pretrained: False\n"
     ]
    }
   ],
   "source": [
    "model = TrainingTestingAgent(epochs = epochs,\n",
    "                             model = ViTnet,\n",
    "                             get_reward_every = get_reward_every,\n",
    "                             buffer_batch_size = buffer_batch_size,\n",
    "                             batch_size = batch_size,\n",
    "                             env = env,\n",
    "                             att_dim = att_dim,\n",
    "                             n_patches = total_patches,\n",
    "                             buffer_size = buffer_size,\n",
    "                             gamma = gamma,\n",
    "                             tau = tau,\n",
    "                             update_every = update_every,\n",
    "                             lr = lr,\n",
    "                             eps_end = eps_end,\n",
    "                             eps_start = eps_start,\n",
    "                             eps_decay = eps_decay,\n",
    "                             train_loader = train_loader,\n",
    "                             validation_loader = validation_loader,\n",
    "                             device = device,\n",
    "                             dqn_input_size=dqn_input_size,\n",
    "                             pretrained=pretrained)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train SimpleViT (no patch selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop for SimpleViT\n",
    "def train_simple_vit(model, train_loader, criterion, optimizer, device, num_epochs):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader)}\")\n",
    "\n",
    "\n",
    "trainSimple = False\n",
    "\n",
    "if trainSimple:\n",
    "    \n",
    "    # Define the device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Initialize the SimpleViT model, criterion, and optimizer\n",
    "    model = SimpleViT(\n",
    "        image_size = img_size,\n",
    "        patch_size = patch_size,\n",
    "        num_classes = len(classes),\n",
    "        dim = att_dim,\n",
    "        depth = 6,\n",
    "        heads = 16,\n",
    "        mlp_dim = 512).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    train_simple_vit(model, train_loader, criterion, optimizer, device, num_epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "38RJhPQMAaXd"
   },
   "source": [
    "### Train AgentViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g81PySpAHgc5",
    "outputId": "fd09feae-319a-47ef-d363-bc7e7e0aac88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/100\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "initial = time.time()\n",
    "step_reward, selected_patch = model.train_test()\n",
    "print(f'Total Time: {time.time()-initial}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nFrUrs52AXj2"
   },
   "source": [
    "<h3> Train and Validation Informations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UgD0RgDZPBIV",
    "outputId": "e3aa62ca-d622-4ed7-b0cb-f28ab5b3f5d9"
   },
   "outputs": [],
   "source": [
    "results_train = model.train_info()\n",
    "train_loss = results_train['train_loss']\n",
    "train_time = results_train['train_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "PkaW5esyAWin"
   },
   "outputs": [],
   "source": [
    "results_validation = model.validation_info()\n",
    "validation_loss = results_validation['validation_loss']\n",
    "validation_acc = results_validation['validation_acc']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hs_EI4dyQVbn"
   },
   "source": [
    "<h3> Saving Results in CSV format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "v2_mduauQVbn"
   },
   "outputs": [],
   "source": [
    "save_name=\"halfres_pretrained-frozen-cnn_default-configs_8patch_rebalanceR\"\n",
    "\n",
    "df = pd.DataFrame(results_train)\n",
    "\n",
    "df.to_csv(f'{results_save_path_agent}{dataset_name}_train_lowres_dr_e100_{save_name}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "UaCe4CUbAqs0"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results_validation)\n",
    "\n",
    "df.to_csv(f'{results_save_path_agent}{dataset_name}_validation_lowres_dr_e100_{save_name}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LRuW0NCbi57h"
   },
   "source": [
    "### Plot of Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PyzpwMapQVbo"
   },
   "source": [
    "<h3> Train Loss during iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "9wQo9_t_QVbo",
    "outputId": "57003f85-d749-4545-9e65-93b3fa5e7e7b"
   },
   "outputs": [],
   "source": [
    "model_name = \"half-Res Pretrained frozen CNN (Default Configs), 8x8 patches, ReBalance Reward\"\n",
    "\n",
    "plt.plot(range(len(train_loss)), train_loss, label='Train Loss')\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Loss over time: {}'.format(model_name))\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LauYoQB1i_Rn"
   },
   "source": [
    "<h3> Validation Loss during epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "C2SINTgRBXoP",
    "outputId": "0cafe198-6549-466e-b87e-1dc20ec356e9"
   },
   "outputs": [],
   "source": [
    "plt.plot(range(len(validation_loss)), validation_loss, label='Validation Loss')\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Loss over time: {}'.format(model_name))\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XidgR27RQVbo"
   },
   "source": [
    "<h3> Validation Accuracy during epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "SU4iIA1hQVbp",
    "outputId": "8a8032f0-201d-42f3-8cce-9cb8b4d480a0"
   },
   "outputs": [],
   "source": [
    "x = range(len(validation_acc))\n",
    "y = validation_acc\n",
    "\n",
    "plt.plot(x, y, label='Validation Accuracy')\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Accuracy over time: {}'.format(model_name))\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ISnRZwlzjtmK",
    "outputId": "d3d9b68f-fb7d-4cf2-d90e-9a0d5671edcd"
   },
   "outputs": [],
   "source": [
    "validation_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bJ6icTgAp8Vb"
   },
   "source": [
    "## Evaluation for different Heuristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "xmu5b4veuD5r"
   },
   "outputs": [],
   "source": [
    "def evaluate_agent(agent, data_load, device, mode = False):\n",
    "\n",
    "    agent.eval()\n",
    "\n",
    "    elements = 0\n",
    "    csamp = 0\n",
    "    tloss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in data_load:\n",
    "\n",
    "            elements += len(data)\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            state = env.get_state(data)\n",
    "\n",
    "            if mode == \"agent\":\n",
    "              action = model.agent.select_action(state)\n",
    "            elif mode == \"random\":\n",
    "              action = model.env.action_space.sample()\n",
    "            else:\n",
    "              action = torch.tensor([1 for i in range(len(model.env.action_space.sample()))], dtype = torch.float)\n",
    "\n",
    "            ViTnet.set_patches(action)\n",
    "\n",
    "            output = functional.log_softmax(agent(data), dim=1)\n",
    "            loss = functional.nll_loss(output, target, reduction='sum')\n",
    "            _, pred = torch.max(output, dim=1)\n",
    "\n",
    "            tloss += loss.item()\n",
    "            csamp += pred.eq(target).sum()\n",
    "\n",
    "    loss_val = tloss / elements\n",
    "    acc_val = (100.0 * csamp / elements).cpu()\n",
    "\n",
    "    print('\\nAverage validation loss: ' + '{:.4f}'.format(loss_val) +\n",
    "          '  Accuracy:' + '{:5}'.format(csamp) + '/' +\n",
    "          '{:5}'.format(elements) + ' (' +\n",
    "          '{:4.2f}'.format(acc_val) + '%)\\n')\n",
    "\n",
    "    return loss_val, acc_val\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "akTharX5RaL8"
   },
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7mrDXnFLRldw"
   },
   "source": [
    "<h3> All Patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qk6xh-DBwAK6",
    "outputId": "9d32f328-c44a-4052-e5cc-5d6a88369e62"
   },
   "outputs": [],
   "source": [
    "evaluate_agent(ViTnet, train_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "usZfBwXwRqx-"
   },
   "source": [
    "<h3> Patches Selected By agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jKZ0-kJENBnT",
    "outputId": "470618d8-e23d-4caf-8a9a-3c86ba4e6bb2"
   },
   "outputs": [],
   "source": [
    "# time-dependent reward component\n",
    "evaluate_agent(ViTnet, train_loader, device, mode = \"agent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g46_tdT9Rtg3"
   },
   "source": [
    "<h3> Random Patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i-BY6MmuwN8a",
    "outputId": "e8d96322-8dcb-403a-c299-c9e7d93a5d52"
   },
   "outputs": [],
   "source": [
    "evaluate_agent(ViTnet, train_loader, device, mode = \"random\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VY2VipXRejU"
   },
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uygahgWaRx2P"
   },
   "source": [
    "<h3> All Patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ROoB1IPaNGAB",
    "outputId": "8db4e6b0-02ae-4091-9c98-1080f652a65c"
   },
   "outputs": [],
   "source": [
    "evaluate_agent(ViTnet, test_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FPKqXZkxRwNO"
   },
   "source": [
    "<h3> Patches Selected By agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmkSeWCPNJZg",
    "outputId": "5725c11e-76a1-4870-c6ec-4d71f2c1586c"
   },
   "outputs": [],
   "source": [
    "evaluate_agent(ViTnet, test_loader, device, mode = \"agent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "feUitG6eRzss"
   },
   "source": [
    "<h3> Random Patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XcSSTkULckjY",
    "outputId": "8e7bc85e-31d4-4110-92b3-87d6f3e5a976"
   },
   "outputs": [],
   "source": [
    "evaluate_agent(ViTnet, test_loader, device, mode = \"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "weElHDyUNTOh"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
