{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rXC93PvZHALw"
   },
   "source": [
    "# Secondary Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will be expanding on the base experiments by enhancing our RL Agent and Training Agents with various improvements. The research questions we seek to answer include:\n",
    "<ul>\n",
    "<li> How does the agent improve in patch selection and in accelerating training if it is trained over multiple ViT training runs, rather than just one?\n",
    "<li> How does prioritized experience replay improve path selection?\n",
    "<li> How might an RL agent also select images to be used for the minibatch?\n",
    "<li> Would using dropout improve either the DQN or the ViT?\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JBzM4-qJKiU8",
    "outputId": "08d1421b-3897-41ba-dc56-cc6f8af92c99"
   },
   "outputs": [],
   "source": [
    "# !pip install einops\n",
    "# !pip install vit_pytorch\n",
    "# !pip install torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "bBKm4O3pn19s"
   },
   "outputs": [],
   "source": [
    "models_save_path        = \"./model\"\n",
    "results_save_path_agent = \"./result\"\n",
    "dataset_path            = \"./dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Yt6SLbwUnu6r"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jX7uYCACg2j5",
    "outputId": "5c9f9e3e-df84-450e-bcf0-757d4d0ed93b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\patrick\\documents\\github\\bio-agentvit\\.venv\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\patrick\\documents\\github\\bio-agentvit\\.venv\\lib\\site-packages (from scikit-learn) (2.2.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\patrick\\documents\\github\\bio-agentvit\\.venv\\lib\\site-packages (from scikit-learn) (1.15.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\patrick\\documents\\github\\bio-agentvit\\.venv\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\patrick\\documents\\github\\bio-agentvit\\.venv\\lib\\site-packages (from scikit-learn) (3.5.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Libraries for data handling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Libraries for image manipulation and machine learning\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional\n",
    "import torch.optim as optim\n",
    "\n",
    "# Library to load in tinyimagenet\n",
    "from tinyimagenet import TinyImageNet\n",
    "from pathlib import Path\n",
    "\n",
    "!pip install scikit-learn\n",
    "\n",
    "# Libraries for model evaluation metrics\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Libraries for tensor manipulation\n",
    "from einops import rearrange\n",
    "from einops.layers.torch import Rearrange\n",
    "\n",
    "# Libraries for simulation environments (gym)\n",
    "import gym\n",
    "\n",
    "# Libraries for data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Other common libraries\n",
    "from collections import namedtuple\n",
    "import math\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "\n",
    "from dqn_agent import *\n",
    "from train_test_agent import *\n",
    "from rl_env import *\n",
    "from vit import *\n",
    "from viz import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_test_agent import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xi1SBM-8TRqg"
   },
   "source": [
    "<h3> Seed and Device setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "zIBVHD-TTU6u"
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qL0i8NnGpUPc",
    "outputId": "2d665f9f-2adc-42f7-8b92-e02734d89632"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Usings CPU for all devices.\n",
      "Device for our model: cpu\n",
      "Device for their model: cpu\n",
      "Device for baseline model: cpu\n"
     ]
    }
   ],
   "source": [
    "num_cuda_devices = torch.cuda.device_count()\n",
    "print(num_cuda_devices)\n",
    "if num_cuda_devices == 0:\n",
    "    # raise ValueError(\"Not enough CUDA devices available. At least 3 are required.\")\n",
    "    device_our = torch.device('cpu')\n",
    "    device_their = torch.device('cpu')\n",
    "    device_baseline = torch.device('cpu')\n",
    "    \n",
    "    print(\"Usings CPU for all devices.\")\n",
    "\n",
    "elif num_cuda_devices == 1:\n",
    "    device_our = torch.device('cuda:0')\n",
    "    device_their = torch.device('cuda:0')\n",
    "    device_baseline = torch.device('cuda:0')\n",
    "\n",
    "    print(f\"Using single CUDA device: {device_our}\")\n",
    "\n",
    "else:\n",
    "    device_our = torch.device('cuda:0')\n",
    "    device_their = torch.device('cuda:1')\n",
    "    device_baseline = torch.device('cuda:2')\n",
    "\n",
    "print(f\"Device for our model: {device_our}\")\n",
    "print(f\"Device for their model: {device_their}\")\n",
    "print(f\"Device for baseline model: {device_baseline}\")\n",
    "\n",
    "\n",
    "# device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "# print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ng75uqlIgCvl"
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "diI87IeqHIE5"
   },
   "source": [
    "<h3> Dataset Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "XLxr6JMmgP0g"
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "## Define what dataset we're using.\n",
    "datasets = [\"tinyimagenet\", \"cifar10\"]\n",
    "dataset_idx = 1\n",
    "dataset_name = datasets[dataset_idx]\n",
    "use_subset = False\n",
    "subset_classes = 20\n",
    "load_indices = True\n",
    "\n",
    "if dataset_idx == 0:\n",
    "    img_size = 64\n",
    "    if use_subset:\n",
    "        dataset_name = f\"{dataset_name}_{subset_classes}_subset\"\n",
    "    else:\n",
    "        dataset_name = f\"{dataset_name}\"\n",
    "elif dataset_idx == 1:\n",
    "    img_size = 32\n",
    "    use_subset = False\n",
    "    load_indices = False\n",
    "        \n",
    "    \n",
    "\n",
    "# img_size = 64\n",
    "# dataset_name = \"CIFAR10_BIG_\"\n",
    "# dataset_name = \"TinyImageNet\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SWAh2lXxHQhL"
   },
   "source": [
    "## Train, validation and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TPPcrxFQHS-r",
    "outputId": "cbe50baf-afea-4d6f-f470-8713f6c05682"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Dataset downloaded!\n",
      "['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(img_size, padding=8),\n",
    "    transforms.Resize(img_size),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=TinyImageNet.mean, std=TinyImageNet.std),\n",
    "])\n",
    "\n",
    "transform_validation = transforms.Compose([\n",
    "    transforms.Resize(img_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=TinyImageNet.mean, std=TinyImageNet.std),\n",
    "])\n",
    "\n",
    "# Prepare and load TinyImageNet dataset\n",
    "if (dataset_idx == 0):\n",
    "    trainset_pure = TinyImageNet(Path(\"~/.torchvision/tinyimagenet/\"),split=\"train\",imagenet_idx=False)\n",
    "    trainset =      TinyImageNet(Path(\"~/.torchvision/tinyimagenet/\"),split=\"train\",imagenet_idx=False, transform=transform_train)\n",
    "    validationset = TinyImageNet(Path(\"~/.torchvision/tinyimagenet/\"),split=\"val\",imagenet_idx=False, transform=transform_validation)\n",
    "\n",
    "# Prepare/download CIFAR10 dataset\n",
    "if (dataset_idx == 1):\n",
    "    trainset_pure = torchvision.datasets.CIFAR10(root=dataset_path, train=True, download=True)\n",
    "    trainset =      torchvision.datasets.CIFAR10(root=dataset_path, train=True, download=True, transform=transform_train)\n",
    "    validationset = torchvision.datasets.CIFAR10(root=dataset_path, train=False, download=True, transform=transform_validation)\n",
    "\n",
    "print(\"Dataset downloaded!\")\n",
    "# Only select 20 classes from tinyimagenet.\n",
    "if use_subset:\n",
    "    print(\"Using subset of {} classes\".format(subset_classes))\n",
    "     # Select 20 random classes\n",
    "    selected_classes = list(range(subset_classes))\n",
    "    class_to_idx = {cls: idx for idx, cls in enumerate(selected_classes)}\n",
    "\n",
    "    # Create a mapping from class indices to new indices\n",
    "    start_time = time.time()\n",
    "    # Filter the dataset to include only the selected classes\n",
    "    train_indices_file = 'train_subset_indices_{subset_classes}class.csv'\n",
    "    val_indices_file = 'val_subset_indices_{subset_classes}.csv'\n",
    "\n",
    "    if os.path.exists(train_indices_file) and os.path.exists(val_indices_file) and load_indices:\n",
    "        print(\"Loading subset indices from files...\")\n",
    "        with open(train_indices_file, 'r') as file:\n",
    "            reader = csv.reader(file)\n",
    "            train_subset_indices = list(map(int, next(reader)))\n",
    "\n",
    "        with open(val_indices_file, 'r') as file:\n",
    "            reader = csv.reader(file)\n",
    "            val_subset_indices = list(map(int, next(reader)))\n",
    "    else:\n",
    "        print(\"Computing subset indices...\")\n",
    "        start_time = time.time()\n",
    "        train_subset_indices = [i for i, (_, label) in enumerate(validationset) if label in selected_classes]\n",
    "        val_subset_indices = [i for i, (_, label) in enumerate(trainset) if label in selected_classes]\n",
    "        total_time = time.time() - start_time\n",
    "        print(f\"Time taken to compute subset indices: {total_time:.2f} seconds\")\n",
    "        with open('train_subset_indices_{subset_classes}class.csv', 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(train_subset_indices)\n",
    "\n",
    "        with open('val_subset_indices_{subset_classes}.csv', 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(val_subset_indices)\n",
    "    # train_subset_indices = [i for i, (_, label) in enumerate(validationset) if label in selected_classes]\n",
    "    # val_subset_indices = [i for i, (_, label) in enumerate(trainset) if label in selected_classes]\n",
    "\n",
    "    val_subset = data.Subset(validationset, train_subset_indices)\n",
    "    train_subset = data.Subset(trainset, val_subset_indices)\n",
    "\n",
    "    \n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_subset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "    print(\"trainloader created successfully.\")\n",
    "    dataset_size = len(val_subset)\n",
    "    validation_size = int(0.95 * dataset_size)\n",
    "    test_size = dataset_size - validation_size\n",
    "\n",
    "    print(\"spltting dataset into validation and test sets...\")\n",
    "    val_subset, test_subset = data.random_split(val_subset, [validation_size, test_size])\n",
    "\n",
    "    validation_loader = torch.utils.data.DataLoader(val_subset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "    test_loader = torch.utils.data.DataLoader(test_subset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "    classes = class_to_idx\n",
    "    print(len(np.unique(val_subset.indices)))\n",
    "    print(len(np.unique(train_subset.indices)))\n",
    "\n",
    "else:\n",
    "    dataset_size = len(validationset)\n",
    "    validation_size = int(0.95 * dataset_size)\n",
    "    test_size = dataset_size - validation_size\n",
    "    validationset, testset = data.random_split(validationset, [validation_size, test_size])\n",
    "    train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "    validation_loader = torch.utils.data.DataLoader(validationset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "    test_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "    classes = trainset.classes\n",
    "\n",
    "# classes = trainset.classes\n",
    "\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_4JC4EFqtfK5"
   },
   "source": [
    "# Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YL2DwKZ1Mdkr"
   },
   "source": [
    "### Functions for training and validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S9IYQ9yHAUwe"
   },
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "TaR2dDv2MQaV"
   },
   "outputs": [],
   "source": [
    "buffer_batch_size = 8\n",
    "buffer_size = 64\n",
    "\n",
    "gamma = 0.95\n",
    "\n",
    "eps_start = 1\n",
    "eps_end = 0.01\n",
    "eps = eps_start\n",
    "eps_decay = 20000\n",
    "\n",
    "lr = 0.01\n",
    "\n",
    "tau = 0.1\n",
    "update_every = 2\n",
    "\n",
    "get_reward_every = 10\n",
    "\n",
    "ourPretrained = False  # Pretrained with CIFAR10 weights, that is.\n",
    "pretrained = False\n",
    "verbose = False     # Whether to print out training progress or not\n",
    "\n",
    "max_reward = 10\n",
    "alpha = 0.2 # Where alpha defines weight of loss reward, and 1-alpha defines weight of patch (time) reward\n",
    "# loss_weight = max_reward*(alpha)  # TODO THIS ONE TOO\n",
    "# time_weight = max_reward*(1-alpha) # TODO PLAY WITH THESE VALUES A LOT\n",
    "loss_weight = alpha\n",
    "time_weight = 1-alpha\n",
    "\n",
    "# Input image to DQN agent's  Q-network\n",
    "# for CIFAR, lowres=16, fullres=32\n",
    "# For TinyImageNet, halfres = 32, fullres = 64\n",
    "dqn_img_w = img_size // 2\n",
    "dqn_input_channels = 3\n",
    "dqn_input_size = dqn_img_w*dqn_img_w*dqn_input_channels # input to DQN (mlp type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vl8vY8iKrKbW",
    "outputId": "a006f5e7-e1f7-40c0-c6d7-d5469e24b1c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    }
   ],
   "source": [
    "# This is the number of patches along the width/height of the square image.\n",
    "# TODO refactor...img_size is defined WAY up in the notebook, right before dataset loader initialization\n",
    "patch_width = 4\n",
    "# patch_size = int(img_size/patch_width)\n",
    "patch_size = patch_width # This is what you get when you work with someone else's code and don't want to rewrite everything.\n",
    "\n",
    "\n",
    "total_patches = int((img_size/patch_width)**2)\n",
    "print(total_patches)\n",
    "n_patch_selected = int(total_patches*(40/64)) # From the paper\n",
    "\n",
    "\n",
    "att_dim = 128\n",
    "\n",
    "epochs = 20\n",
    "save_every = 10\n",
    "learning_rate = 0.001\n",
    "\n",
    "\n",
    "# Definte the three transformer models.\n",
    "SimpleAgentViTnet = SimpleAgentViT(\n",
    "    image_size = img_size,\n",
    "    patch_size = patch_size,\n",
    "    num_classes = len(classes),\n",
    "    dim = att_dim,\n",
    "    depth = 6,\n",
    "    heads = 16,\n",
    "    mlp_dim = 512\n",
    ")\n",
    "\n",
    "OurViTnet = SimpleAgentViT(\n",
    "    image_size = img_size,\n",
    "    patch_size = patch_size,\n",
    "    num_classes = len(classes),\n",
    "    dim = att_dim,\n",
    "    depth = 6,\n",
    "    heads = 16,\n",
    "    mlp_dim = 512\n",
    ")\n",
    "\n",
    "BaselineSimpleViT = SimpleViT(\n",
    "    image_size = img_size,\n",
    "    patch_size = patch_size,\n",
    "    num_classes = len(classes),\n",
    "    dim = att_dim,\n",
    "    depth = 6,\n",
    "    heads = 16,\n",
    "    mlp_dim = 512\n",
    ")\n",
    "\n",
    "# Sposta il modello sulla GPU (se disponibile)\n",
    "SimpleAgentViTnet.to(device_their)\n",
    "OurViTnet.to(device_our)\n",
    "BaselineSimpleViT.to(device_baseline)\n",
    "    \n",
    "# definiamo l'ottimizzatore\n",
    "SimpleOptimizer =   optim.Adam(SimpleAgentViTnet.parameters(), lr=learning_rate)\n",
    "OurOptimizer =      optim.Adam(OurViTnet.parameters(), lr=learning_rate)\n",
    "BaselineOptimizer = optim.Adam(BaselineSimpleViT.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "_ernM9pqoxbd"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#env = ViTEnv(ViTnet, total_patches, optimizer, loss_weight, time_weight, device, n_patch_selected)\n",
    "theirEnv = ViTEnv(SimpleAgentViTnet, total_patches, SimpleOptimizer, loss_weight, time_weight, device_their, n_patch_selected, verbose=verbose, total_epochs=epochs)\n",
    "ourEnv = OurViTEnv(OurViTnet, total_patches, OurOptimizer, loss_weight, time_weight, device_our, n_patch_selected, verbose=verbose, total_epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iRn2Tplb90tO",
    "outputId": "41f4a30b-3136-4e9e-a179-097a5081f65f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNet created! Value of pretrained: False\n",
      "ConvNet created! Value of pretrained: False\n"
     ]
    }
   ],
   "source": [
    "ourModel = OurTrainingTestingAgent(epochs = epochs,\n",
    "                             model = OurViTnet,\n",
    "                             get_reward_every = get_reward_every,\n",
    "                             buffer_batch_size = buffer_batch_size,\n",
    "                             batch_size = batch_size,\n",
    "                             env = ourEnv,\n",
    "                             att_dim = att_dim,\n",
    "                             n_patches = total_patches,\n",
    "                             buffer_size = buffer_size,\n",
    "                             gamma = gamma,\n",
    "                             tau = tau,\n",
    "                             update_every = update_every,\n",
    "                             lr = lr,\n",
    "                             eps_end = eps_end,\n",
    "                             eps_start = eps_start,\n",
    "                             eps_decay = eps_decay,\n",
    "                             train_loader = train_loader,\n",
    "                             validation_loader = validation_loader,\n",
    "                             device = device_our,\n",
    "                             dqn_input_size=dqn_input_size,\n",
    "                             patch_size=patch_size,\n",
    "                             save_every=save_every,\n",
    "                             verbose=verbose,\n",
    "                             pretrained=ourPretrained)\n",
    "\n",
    "theirModel = TrainingTestingAgent(epochs = epochs,\n",
    "                             model = SimpleAgentViTnet,\n",
    "                             get_reward_every = get_reward_every,\n",
    "                             buffer_batch_size = buffer_batch_size,\n",
    "                             batch_size = batch_size,\n",
    "                             env = theirEnv,\n",
    "                             att_dim = att_dim,\n",
    "                             n_patches = total_patches,\n",
    "                             buffer_size = buffer_size,\n",
    "                             gamma = gamma,\n",
    "                             tau = tau,\n",
    "                             update_every = update_every,\n",
    "                             lr = lr,\n",
    "                             eps_end = eps_end,\n",
    "                             eps_start = eps_start,\n",
    "                             eps_decay = eps_decay,\n",
    "                             train_loader = train_loader,\n",
    "                             validation_loader = validation_loader,\n",
    "                             patch_size=patch_size,\n",
    "                             save_every=save_every,\n",
    "                             verbose=verbose,\n",
    "                             device = device_their)\n",
    "\n",
    "baselineModel = SimpleViTTrainingTestingAgent(epochs = epochs,\n",
    "                             batch_size = batch_size, \n",
    "                             model = BaselineSimpleViT,\n",
    "                             train_loader = train_loader, \n",
    "                             validation_loader = validation_loader, \n",
    "                             device = device_baseline,\n",
    "                             optimizer=BaselineOptimizer, \n",
    "                            #  criterion=criterion,\n",
    "                             save_every=save_every, \n",
    "                             verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: True\n",
      "_parameters: {}\n",
      "_buffers: {}\n",
      "_non_persistent_buffers_set: set()\n",
      "_backward_pre_hooks: OrderedDict()\n",
      "_backward_hooks: OrderedDict()\n",
      "_is_full_backward_hook: None\n",
      "_forward_hooks: OrderedDict()\n",
      "_forward_hooks_with_kwargs: OrderedDict()\n",
      "_forward_hooks_always_called: OrderedDict()\n",
      "_forward_pre_hooks: OrderedDict()\n",
      "_forward_pre_hooks_with_kwargs: OrderedDict()\n",
      "_state_dict_hooks: OrderedDict()\n",
      "_state_dict_pre_hooks: OrderedDict()\n",
      "_load_state_dict_pre_hooks: OrderedDict()\n",
      "_load_state_dict_post_hooks: OrderedDict()\n",
      "_modules: {'to_patch_embedding': Sequential(\n",
      "  (0): Rearrange('b c (h p1) (w p2) -> b h w (p1 p2 c)', p1=4, p2=4)\n",
      "  (1): LayerNorm((48,), eps=1e-05, elementwise_affine=True)\n",
      "  (2): Linear(in_features=48, out_features=128, bias=True)\n",
      "  (3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "), 'transformer': Transformer(\n",
      "  (layers): ModuleList(\n",
      "    (0-5): 6 x ModuleList(\n",
      "      (0): Attention(\n",
      "        (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (attend): Softmax(dim=-1)\n",
      "        (to_qkv): Linear(in_features=128, out_features=3072, bias=False)\n",
      "        (to_out): Linear(in_features=1024, out_features=128, bias=False)\n",
      "      )\n",
      "      (1): FeedForward(\n",
      "        (net): Sequential(\n",
      "          (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (1): Linear(in_features=128, out_features=512, bias=True)\n",
      "          (2): GELU(approximate='none')\n",
      "          (3): Linear(in_features=512, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "), 'to_latent': Identity(), 'linear_head': Sequential(\n",
      "  (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "  (1): Linear(in_features=128, out_features=10, bias=True)\n",
      ")}\n",
      "patches: []\n"
     ]
    }
   ],
   "source": [
    "# for key, value in vars(ourModel).items():\n",
    "#     print(f\"{key}: {value}\")\n",
    "\n",
    "# for key, value in vars(ourEnv).items():\n",
    "#     print(f\"{key}: {value}\")\n",
    "\n",
    "for key, value in vars(OurViTnet).items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2500x500 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Visualize the patch selection and attention scores for the untrained models.\n",
    "## Use functions defined in viz.py\n",
    "# Select a random set of 5 images from the dataset\n",
    "num_images = 5\n",
    "random_indices = np.random.choice(len(trainset_pure), num_images, replace=False)\n",
    "random_images = [trainset_pure[i][0] for i in random_indices]\n",
    "print(trainset_pure[2][1])\n",
    "random_classes = [classes[trainset_pure[i][1]] for i in random_indices] \n",
    "\n",
    "\n",
    "\n",
    "half_norm_transform = transforms.Compose(\n",
    "    [transforms.Resize((img_size // 2, img_size // 2)), \n",
    "    transforms.Normalize(mean=TinyImageNet.mean, std=TinyImageNet.std)]\n",
    "    )\n",
    "\n",
    "# # Visualize the patch selection and attention scores\n",
    "# for img in random_images:\n",
    "#     if dataset_idx == 0:\n",
    "#         input_img = half_norm_transform(img)\n",
    "#     elif dataset_idx == 1:\n",
    "#         input_img = transforms.ToTensor()(img)\n",
    "#         img = transforms.ToTensor()(img)\n",
    "#     visualize_selected_patches(img, input_img, ourModel.agent, device_our)\n",
    "#     # visualize_attention_scores(img, model.ViTnet, device)\n",
    "\n",
    "random_images = [transforms.ToTensor()(img) for img in random_images]\n",
    "visualize_selected_patches_multiple_images(random_images, random_images, ourModel.agent, device_our, titles=[\"Our Model, class \" + str(random_classes[i]) for i in range(num_images)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "38RJhPQMAaXd"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g81PySpAHgc5",
    "outputId": "816f6100-3fe5-4c0b-ecdf-7acd898ae45d"
   },
   "outputs": [],
   "source": [
    "# BioAgentViT\n",
    "def trainModel(model, models_save_path, model_name, dataset_name):\n",
    "    initial = time.time()\n",
    "    step_reward, selected_patch = model.train_test(models_save_path, dataset_name)\n",
    "    print(f'{model_name} Total Training Time: {time.time()-initial}')\n",
    "\n",
    "def plotTrainingInfo(model, model_name, dataset_name):\n",
    "    # Collect train and validation information\n",
    "    our_train_info = pd.DataFrame(model.train_info())\n",
    "    our_validation_info = pd.DataFrame(model.validation_info())\n",
    "\n",
    "    # Extract loss and accuracy information\n",
    "    our_train_loss = our_train_info['train_loss']\n",
    "    our_validation_loss = our_validation_info['validation_loss']\n",
    "    our_validation_acc = our_validation_info['validation_acc']\n",
    "\n",
    "    # Plotting\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "    # Plot training and validation loss\n",
    "    axs[0].plot(range(len(our_train_loss)), our_train_loss, label='Our Model Train Loss')\n",
    "    axs[0].plot(range(len(our_validation_loss)), our_validation_loss, label='Our Model Validation Loss')\n",
    "    axs[0].legend()\n",
    "    axs[0].set_title('Training and Validation Loss for ' + model_name + ' on ' + dataset_name)\n",
    "    axs[0].set_xlabel('Epochs')\n",
    "    axs[0].set_ylabel('Loss')\n",
    "\n",
    "    # Plot validation accuracy\n",
    "    axs[1].plot(range(len(our_validation_acc)), our_validation_acc, label='Our Model Validation Accuracy')\n",
    "    axs[1].legend()\n",
    "    axs[1].set_title('Validation Accuracy for ' + model_name + ' on ' + dataset_name)\n",
    "    axs[1].set_xlabel('Epochs')\n",
    "    axs[1].set_ylabel('Accuracy')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question: How does the agent improve in patch selection and in accelerating training if it is trained over multiple ViT training runs, rather than just one?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1/5\n",
      "Epoch: 1/20\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_iterations):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIteration \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_iterations\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m     \u001b[43mtrainModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mourModel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodels_save_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mOur Model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     plotTrainingInfo(ourModel, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOur Model\u001b[39m\u001b[38;5;124m\"\u001b[39m, dataset_name)\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# visualize patch selection\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[16], line 4\u001b[0m, in \u001b[0;36mtrainModel\u001b[1;34m(model, models_save_path, model_name, dataset_name)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtrainModel\u001b[39m(model, models_save_path, model_name, dataset_name):\n\u001b[0;32m      3\u001b[0m     initial \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m----> 4\u001b[0m     step_reward, selected_patch \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodels_save_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Total Training Time: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;241m-\u001b[39minitial\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Patrick\\Documents\\GitHub\\Bio-AgentViT\\train_test_agent.py:90\u001b[0m, in \u001b[0;36mOurTrainingTestingAgent.train_test\u001b[1;34m(self, models_save_path, dataset_name)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;66;03m# alleno\u001b[39;00m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_reward_every \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m---> 90\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpatch_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;66;03m# alleno e testo il ViT\u001b[39;00m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     94\u001b[0m   new_state, reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mstep_reward(patch_list, data, target)\n",
      "File \u001b[1;32mc:\\Users\\Patrick\\Documents\\GitHub\\Bio-AgentViT\\rl_env.py:123\u001b[0m, in \u001b[0;36mOurViTEnv.step_train\u001b[1;34m(self, action, train_data, train_target)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstep_train\u001b[39m(\u001b[38;5;28mself\u001b[39m, action, train_data, train_target):\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mViTnet\u001b[38;5;241m.\u001b[39mset_patches(action)\n\u001b[1;32m--> 123\u001b[0m     \u001b[43mtrain_iter_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mViTnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_target\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Patrick\\Documents\\GitHub\\Bio-AgentViT\\rl_env.py:34\u001b[0m, in \u001b[0;36mtrain_iter_agent\u001b[1;34m(model, optimizer, data, target)\u001b[0m\n\u001b[0;32m     31\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m     33\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 34\u001b[0m out \u001b[38;5;241m=\u001b[39m functional\u001b[38;5;241m.\u001b[39mlog_softmax(\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     35\u001b[0m loss \u001b[38;5;241m=\u001b[39m functional\u001b[38;5;241m.\u001b[39mnll_loss(out, target)\n\u001b[0;32m     36\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\Patrick\\Documents\\GitHub\\Bio-AgentViT\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Patrick\\Documents\\GitHub\\Bio-AgentViT\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Patrick\\Documents\\GitHub\\Bio-AgentViT\\vit.py:119\u001b[0m, in \u001b[0;36mSimpleAgentViT.forward\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m    116\u001b[0m mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatches, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mbool)\n\u001b[0;32m    117\u001b[0m x \u001b[38;5;241m=\u001b[39m x[:, mask, :]\n\u001b[1;32m--> 119\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    121\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mmean(dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    123\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_latent(x)\n",
      "File \u001b[1;32mc:\\Users\\Patrick\\Documents\\GitHub\\Bio-AgentViT\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Patrick\\Documents\\GitHub\\Bio-AgentViT\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Patrick\\Documents\\GitHub\\Bio-AgentViT\\vit.py:75\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m attn, ff \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m---> 75\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m x\n\u001b[0;32m     76\u001b[0m         x \u001b[38;5;241m=\u001b[39m ff(x) \u001b[38;5;241m+\u001b[39m x\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\Patrick\\Documents\\GitHub\\Bio-AgentViT\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Patrick\\Documents\\GitHub\\Bio-AgentViT\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Patrick\\Documents\\GitHub\\Bio-AgentViT\\vit.py:62\u001b[0m, in \u001b[0;36mAttention.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     60\u001b[0m out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(attn, v)\n\u001b[0;32m     61\u001b[0m out \u001b[38;5;241m=\u001b[39m rearrange(out, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb h n d -> b n (h d)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 62\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_out\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Patrick\\Documents\\GitHub\\Bio-AgentViT\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Patrick\\Documents\\GitHub\\Bio-AgentViT\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Patrick\\Documents\\GitHub\\Bio-AgentViT\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_iterations = 5\n",
    "\n",
    "for i in range(num_iterations):\n",
    "    print(f\"Iteration {i+1}/{num_iterations}\")\n",
    "    trainModel(ourModel, models_save_path, \"Our Model\", dataset_name)\n",
    "    plotTrainingInfo(ourModel, \"Our Model\", dataset_name)\n",
    "    # visualize patch selection\n",
    "    visualize_selected_patches_multiple_images(random_images, random_images, ourModel.agent, device_our, titles=[\"Our Model, class \" + str(random_classes[i]) for i in range(num_images)])\n",
    "    # Reassign the ViT model to the agent AND to the environment\n",
    "    # Destroy the old model first\n",
    "    del ourModel.env.ViTnet \n",
    "    del ourModel.ViTnet\n",
    "    del ourModel.env.optimizer\n",
    "    \n",
    "    # Reset the ViT model after training.\n",
    "    # Maintain the DQN for re-training/fine-tuning.\n",
    "    OurViTnet = SimpleAgentViT(\n",
    "    image_size = img_size,\n",
    "    patch_size = patch_size,\n",
    "    num_classes = len(classes),\n",
    "    dim = att_dim,\n",
    "    depth = 6,\n",
    "    heads = 16,\n",
    "    mlp_dim = 512\n",
    ")\n",
    "    # Send the model to the device (cuda or cpu) \n",
    "    OurViTnet.to(device_our)\n",
    "    \n",
    "    ourModel.ViTnet = OurViTnet\n",
    "    ourModel.env.ViTnet = OurViTnet\n",
    "\n",
    "    # Reassign the optimizer to the new parameters \n",
    "    opt = optim.Adam(OurViTnet.parameters(), lr=learning_rate)\n",
    "    ourModel.optimizer = opt\n",
    "    ourModel.env.optimizer = opt\n",
    "    \n",
    "    \n",
    "# Do the same but for theirModel\n",
    "for i in range(num_iterations):\n",
    "    print(f\"Iteration {i+1}/{num_iterations}\")\n",
    "    trainModel(theirModel, models_save_path, \"Their Model\", dataset_name)\n",
    "    plotTrainingInfo(theirModel, \"Their Model\", dataset_name)\n",
    "    \n",
    "    # Reassign the ViT model to the agent AND to the environment\n",
    "    # Destroy the old model first\n",
    "    del theirModel.ViTnet \n",
    "    del theirModel.env.ViTnet\n",
    "    # del theirModel.optimizer\n",
    "    del theirModel.env.optimizer\n",
    "    \n",
    "    # Reset the ViT model after training.\n",
    "    # Maintain the DQN for re-training/fine-tuning.\n",
    "    theirViTnet = SimpleAgentViT(\n",
    "        image_size = img_size,\n",
    "        patch_size = patch_size,\n",
    "        num_classes = len(classes),\n",
    "        dim = att_dim,\n",
    "        depth = 6,\n",
    "        heads = 16,\n",
    "        mlp_dim = 512\n",
    "    )\n",
    "    # Send the model to the device (cuda or cpu) \n",
    "    theirViTnet.to(device_their)\n",
    "    \n",
    "    theirModel.ViTnet = theirViTnet\n",
    "    theirModel.env.ViTnet = theirViTnet\n",
    "\n",
    "    # Reassign the optimizer to the new parameters \n",
    "    opt = optim.Adam(theirViTnet.parameters(), lr=learning_rate)\n",
    "    # theirModel.optimizer = opt # Evidently, their training agent does not have an optimizer member. Only ours does. But I believe it does not use it, only the rl_env uses it.\n",
    "    theirModel.env.optimizer = opt\n",
    "    \n",
    "# trainModel(ourModel, models_save_path, \"Our Model\", dataset_name)\n",
    "# trainModel(theirModel, models_save_path, \"Their Model\", dataset_name)\n",
    "# trainModel(baselineModel, models_save_path, \"Baseline Model\", dataset_name)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nFrUrs52AXj2"
   },
   "source": [
    "<h3> Train and Validation Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PkaW5esyAWin"
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Collect train and validation information from each model\n",
    "our_train_info = pd.DataFrame(ourModel.train_info())\n",
    "our_validation_info = pd.DataFrame(ourModel.validation_info())\n",
    "\n",
    "their_train_info = pd.DataFrame(theirModel.train_info())\n",
    "their_validation_info = pd.DataFrame(theirModel.validation_info())\n",
    "\n",
    "baseline_train_info = pd.DataFrame(baselineModel.train_info())\n",
    "baseline_validation_info = pd.DataFrame(baselineModel.validation_info())\n",
    "\n",
    "# Save the training and validation information to the ./results folder\n",
    "results_folder = \"./results\"\n",
    "\n",
    "# Ensure the results folder exists\n",
    "os.makedirs(results_folder, exist_ok=True)\n",
    "\n",
    "# Get the current timestamp\n",
    "timestamp = datetime.datetime.now().strftime(\"%m%d_%H%M\")\n",
    "\n",
    "# Optional user-provided identifier for our model\n",
    "our_model_id = \"default_id\"  # Replace with the actual identifier if provided\n",
    "\n",
    "# Save our model's training and validation info\n",
    "our_train_info.to_csv(os.path.join(results_folder, f\"our_model_train_info_{our_model_id}_{timestamp}.csv\"), index=False)\n",
    "our_validation_info.to_csv(os.path.join(results_folder, f\"our_model_validation_info_{our_model_id}_{timestamp}.csv\"), index=False)\n",
    "\n",
    "# Save their model's training and validation info\n",
    "their_train_info.to_csv(os.path.join(results_folder, f\"their_model_train_info_{timestamp}.csv\"), index=False)\n",
    "their_validation_info.to_csv(os.path.join(results_folder, f\"their_model_validation_info_{timestamp}.csv\"), index=False)\n",
    "\n",
    "# Save baseline model's training and validation info\n",
    "baseline_train_info.to_csv(os.path.join(results_folder, f\"baseline_model_train_info_{timestamp}.csv\"), index=False)\n",
    "baseline_validation_info.to_csv(os.path.join(results_folder, f\"baseline_model_validation_info_{timestamp}.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LRuW0NCbi57h"
   },
   "source": [
    "### Plot of Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PyzpwMapQVbo"
   },
   "source": [
    "<h3> Train/Validation Loss and Train/Val Accuracy Across Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming the training and validation information has been collected in the previous cells\n",
    "# and stored in the variables: our_train_info, our_validation_info, their_train_info, their_validation_info, baseline_train_info, baseline_validation_info\n",
    "\n",
    "# Extract loss and accuracy information\n",
    "our_train_loss = our_train_info['train_loss']\n",
    "our_validation_loss = our_validation_info['validation_loss']\n",
    "# our_train_acc = our_train_info['accuracy']\n",
    "our_validation_acc = our_validation_info['validation_acc']\n",
    "\n",
    "their_train_loss = their_train_info['train_loss']\n",
    "their_validation_loss = their_validation_info['validation_loss']\n",
    "# their_train_acc = their_train_info['accuracy']\n",
    "their_validation_acc = their_validation_info['validation_acc']\n",
    "\n",
    "baseline_train_loss = baseline_train_info['train_loss']\n",
    "baseline_validation_loss = baseline_validation_info['validation_loss']\n",
    "# baseline_train_acc = baseline_train_info['accuracy']\n",
    "baseline_validation_acc = baseline_validation_info['validation_acc']\n",
    "\n",
    "# Plotting\n",
    "fig, axs = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Plot training and validation loss\n",
    "axs[0].plot(range(len(our_train_loss)), our_train_loss, label='Our Model Train Loss')\n",
    "axs[0].plot(range(len(their_train_loss)), their_train_loss, label='Their Model Train Loss')\n",
    "axs[0].plot(range(len(baseline_train_loss)), baseline_train_loss, label='Baseline Model Train Loss')\n",
    "axs[0].plot(range(len(our_validation_loss)), our_validation_loss, label='Our Model Validation Loss')\n",
    "axs[0].plot(range(len(their_validation_loss)), their_validation_loss, label='Their Model Validation Loss')\n",
    "axs[0].plot(range(len(baseline_validation_loss)), baseline_validation_loss, label='Baseline Model Validation Loss')\n",
    "axs[0].legend()\n",
    "axs[0].set_title('Training and Validation Loss')\n",
    "axs[0].set_xlabel('Epochs')\n",
    "axs[0].set_ylabel('Loss')\n",
    "\n",
    "# Plot training and validation accuracy\n",
    "# axs[1].plot(range(len(our_train_acc)), our_train_acc, label='Our Model Train Accuracy')\n",
    "axs[1].plot(range(len(our_validation_acc)), our_validation_acc, label='Our Model Validation Accuracy')\n",
    "# axs[1].plot(range(len(their_train_acc)), their_train_acc, label='Their Model Train Accuracy')\n",
    "axs[1].plot(range(len(their_validation_acc)), their_validation_acc, label='Their Model Validation Accuracy')\n",
    "# axs[1].plot(range(len(baseline_train_acc)), baseline_train_acc, label='Baseline Model Train Accuracy')\n",
    "axs[1].plot(range(len(baseline_validation_acc)), baseline_validation_acc, label='Baseline Model Validation Accuracy')\n",
    "axs[1].legend()\n",
    "axs[1].set_title('Training and Validation Accuracy')\n",
    "axs[1].set_xlabel('Epochs')\n",
    "axs[1].set_ylabel('Accuracy')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bJ6icTgAp8Vb"
   },
   "source": [
    "## Evaluation for different Heuristics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "akTharX5RaL8"
   },
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7mrDXnFLRldw"
   },
   "source": [
    "<h3> All Patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qk6xh-DBwAK6"
   },
   "outputs": [],
   "source": [
    "evaluate_agent(OurViTnet, train_loader, device_our, ourEnv)\n",
    "evaluate_agent(SimpleAgentViTnet, train_loader, device_their, theirEnv)\n",
    "evaluate_agent(BaselineSimpleViT, train_loader, device_baseline, ourEnv)\n",
    "# evaluate_agent(ViTnet, train_loader, device, env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "usZfBwXwRqx-"
   },
   "source": [
    "<h3> Patches Selected By agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jKZ0-kJENBnT"
   },
   "outputs": [],
   "source": [
    "evaluate_agent(OurViTnet, train_loader, device_our, ourEnv, mode=\"agent\")\n",
    "evaluate_agent(SimpleAgentViTnet, train_loader, device_their, theirEnv, mode=\"agent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g46_tdT9Rtg3"
   },
   "source": [
    "<h3> Random Patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i-BY6MmuwN8a"
   },
   "outputs": [],
   "source": [
    "evaluate_agent(OurViTnet, train_loader, device_our, ourEnv, mode=\"random\")\n",
    "evaluate_agent(SimpleAgentViTnet, train_loader, device_their, theirEnv, mode=\"random\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VY2VipXRejU"
   },
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uygahgWaRx2P"
   },
   "source": [
    "<h3> All Patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ROoB1IPaNGAB"
   },
   "outputs": [],
   "source": [
    "evaluate_agent(OurViTnet, validation_loader, device_our, ourEnv)\n",
    "evaluate_agent(OurViTnet, test_loader, device_our, ourEnv)\n",
    "evaluate_agent(SimpleAgentViTnet, validation_loader, device_their, theirEnv)\n",
    "evaluate_agent(SimpleAgentViTnet, test_loader, device_their, theirEnv)\n",
    "evaluate_agent(BaselineSimpleViT, validation_loader, device_baseline, ourEnv)\n",
    "evaluate_agent(BaselineSimpleViT, test_loader, device_baseline, ourEnv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FPKqXZkxRwNO"
   },
   "source": [
    "<h3> Patches Selected By agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_agent(OurViTnet, validation_loader, device_our, ourEnv, mode=\"random\")\n",
    "evaluate_agent(OurViTnet, test_loader, device_our, ourEnv, mode=\"agent\")\n",
    "evaluate_agent(SimpleAgentViTnet, validation_loader, device_their, theirEnv, mode=\"agent\")\n",
    "evaluate_agent(SimpleAgentViTnet, test_loader, device_their, theirEnv, mode=\"agent\")\n",
    "evaluate_agent(BaselineSimpleViT, validation_loader, device_baseline, ourEnv, mode=\"agent\")\n",
    "evaluate_agent(BaselineSimpleViT, test_loader, device_baseline, ourEnv, mode=\"agent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Patches Selected at Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wmkSeWCPNJZg"
   },
   "outputs": [],
   "source": [
    "evaluate_agent(OurViTnet, validation_loader, device_our, ourEnv, mode=\"random\")\n",
    "evaluate_agent(OurViTnet, test_loader, device_our, ourEnv, mode=\"random\")\n",
    "evaluate_agent(SimpleAgentViTnet, validation_loader, device_their, theirEnv, mode=\"random\")\n",
    "evaluate_agent(SimpleAgentViTnet, test_loader, device_their, theirEnv, mode=\"random\")\n",
    "evaluate_agent(BaselineSimpleViT, validation_loader, device_baseline, ourEnv, mode=\"random\")\n",
    "evaluate_agent(BaselineSimpleViT, test_loader, device_baseline, ourEnv, mode=\"random\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_patch_coordinates(patch_index, patch_size, num_patches_per_row):\n",
    "    row = patch_index // num_patches_per_row\n",
    "    col = patch_index % num_patches_per_row\n",
    "    return row * patch_size , col * patch_size\n",
    "\n",
    "def visualize_selected_patches(image, input_img, model_agent, device):\n",
    "    # model_agent.eval()\n",
    "    with torch.no_grad():\n",
    "        patches = model_agent.select_action(input_img.to(device))\n",
    "        patches = [1 if patch > patches.mean() else 0 for patch in patches]\n",
    "    \n",
    "    patch_size = model_agent.patch_size\n",
    "    fig, ax = plt.subplots(1)\n",
    "    ax.imshow(image.permute(1, 2, 0).cpu().numpy())\n",
    "   \n",
    "    # ax.imshow(image.cpu().numpy())\n",
    "    num_patches_per_row = int(image.size(1) // patch_size)\n",
    "    for i, patch in enumerate(patches):\n",
    "        if patch == 0:\n",
    "            y, x = get_patch_coordinates(i, patch_size, num_patches_per_row)\n",
    "            rect = plt.Rectangle((x-1, y-1), patch_size, patch_size, edgecolor='none', facecolor='gray', alpha=0.9)\n",
    "            # rect = plt.Rectangle((x, y), patch_size, patch_size, edgecolor='r', facecolor='none')\n",
    "            ax.add_patch(rect)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def get_image_with_selected_patches(image, input, model_agent, device):\n",
    "    with torch.no_grad():\n",
    "        patches = model_agent.select_action(input.to(device))\n",
    "        patches = [1 if patch > patches.mean() else 0 for patch in patches]\n",
    "    \n",
    "    patch_size = model_agent.patch_size\n",
    "    num_patches_per_row = int(image.size(1) // patch_size)\n",
    "    \n",
    "    image_np = image.permute(1, 2, 0).cpu().numpy()\n",
    "    for i, patch in enumerate(patches):\n",
    "        if patch == 0:\n",
    "            y, x = get_patch_coordinates(i, patch_size, num_patches_per_row)\n",
    "            # Convert all numbers into integers\n",
    "            y = int(y)\n",
    "            x = int(x)\n",
    "            patch_size = int(patch_size)\n",
    "            image_np[y:y+patch_size, x:x+patch_size] = np.array([0.5, 0.5, 0.5])  # Gray color\n",
    "    \n",
    "    return image_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visualize the patch selection and attention scores for the untrained models.\n",
    "## Use functions defined in viz.py\n",
    "# Select a random set of 5 images from the dataset\n",
    "num_images = 3\n",
    "random_indices = np.random.choice(len(trainset_pure), num_images, replace=False)\n",
    "random_images = [trainset_pure[i][0] for i in random_indices]\n",
    "\n",
    "\n",
    "\n",
    "half_norm_transform = transforms.Compose(\n",
    "    [transforms.Resize((img_size // 2, img_size // 2)), \n",
    "    transforms.Normalize(mean=TinyImageNet.mean, std=TinyImageNet.std)]\n",
    "    )\n",
    "\n",
    "fig, axs = plt.subplots(num_images, 2, figsize=(10, 15))\n",
    "\n",
    "for i, img in enumerate(random_images):\n",
    "    input_img = half_norm_transform(img)\n",
    "    \n",
    "    our_patches_img = get_image_with_selected_patches(img, input_img, ourModel.agent, device_our)\n",
    "    their_patches_img = get_image_with_selected_patches(img, img, theirModel.agent, device_their)\n",
    "    \n",
    "    axs[i, 0].imshow(our_patches_img)\n",
    "    axs[i, 0].set_title(\"Our Model\")\n",
    "    axs[i, 0].axis('off')\n",
    "    \n",
    "    axs[i, 1].imshow(their_patches_img)\n",
    "    axs[i, 1].set_title(\"Their Model\")\n",
    "    axs[i, 1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# # Visualize the patch selection and attention scores\n",
    "# for img in random_images:\n",
    "#     input_img = half_norm_transform(img)\n",
    "#     visualize_selected_patches(img, input_img, ourModel.agent, device_our)\n",
    "#     visualize_selected_patches(img, input_img, theirModel.agent, device_their)\n",
    "#     # visualize_attention_scores(img, model.ViTnet, device)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
