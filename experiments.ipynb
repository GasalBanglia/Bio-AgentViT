{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXC93PvZHALw"
      },
      "source": [
        "# Import e path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBzM4-qJKiU8",
        "outputId": "08d1421b-3897-41ba-dc56-cc6f8af92c99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tinyimagenet in /usr/local/lib/python3.11/dist-packages (0.9.9)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from tinyimagenet) (0.20.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision->tinyimagenet) (1.26.4)\n",
            "Requirement already satisfied: torch==2.5.1 in /usr/local/lib/python3.11/dist-packages (from torchvision->tinyimagenet) (2.5.1+cu121)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->tinyimagenet) (11.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision->tinyimagenet) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision->tinyimagenet) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision->tinyimagenet) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision->tinyimagenet) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision->tinyimagenet) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision->tinyimagenet) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision->tinyimagenet) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision->tinyimagenet) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision->tinyimagenet) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision->tinyimagenet) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision->tinyimagenet) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision->tinyimagenet) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision->tinyimagenet) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision->tinyimagenet) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision->tinyimagenet) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision->tinyimagenet) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision->tinyimagenet) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision->tinyimagenet) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.5.1->torchvision->tinyimagenet) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.5.1->torchvision->tinyimagenet) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.5.1->torchvision->tinyimagenet) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "# !pip install einops\n",
        "# !pip install vit_pytorch\n",
        "!pip install tinyimagenet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "bBKm4O3pn19s"
      },
      "outputs": [],
      "source": [
        "models_save_path        = \"./model\"\n",
        "results_save_path_agent = \"./result\"\n",
        "dataset_path            = \"./dataset\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "Yt6SLbwUnu6r"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jX7uYCACg2j5",
        "outputId": "5c9f9e3e-df84-450e-bcf0-757d4d0ed93b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.0)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n"
          ]
        }
      ],
      "source": [
        "# Libraries for data handling\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Libraries for image manipulation and machine learning\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch\n",
        "import torch.utils.data as data\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional\n",
        "import torch.optim as optim\n",
        "\n",
        "# Library to load in tinyimagenet\n",
        "from tinyimagenet import TinyImageNet\n",
        "from pathlib import Path\n",
        "\n",
        "!pip install scikit-learn\n",
        "\n",
        "# Libraries for model evaluation metrics\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "\n",
        "# Libraries for tensor manipulation\n",
        "from einops import rearrange\n",
        "from einops.layers.torch import Rearrange\n",
        "\n",
        "# Libraries for simulation environments (gym)\n",
        "import gym\n",
        "\n",
        "# Libraries for data visualization\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Other common libraries\n",
        "from collections import namedtuple\n",
        "import math\n",
        "import time\n",
        "import os\n",
        "import random\n",
        "\n",
        "from dqn_agent import *\n",
        "from train_test_agent import *\n",
        "from rl_env import *\n",
        "from vit import *\n",
        "from viz import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xi1SBM-8TRqg"
      },
      "source": [
        "<h3> Seed and Device setting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "zIBVHD-TTU6u"
      },
      "outputs": [],
      "source": [
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "set_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qL0i8NnGpUPc",
        "outputId": "2d665f9f-2adc-42f7-8b92-e02734d89632"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ng75uqlIgCvl"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "diI87IeqHIE5"
      },
      "source": [
        "<h3> Dataset Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "XLxr6JMmgP0g"
      },
      "outputs": [],
      "source": [
        "batch_size = 128\n",
        "img_size = 64\n",
        "# dataset_name = \"CIFAR10_BIG_\"\n",
        "# dataset_name = \"TinyImageNet\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWAh2lXxHQhL"
      },
      "source": [
        "## Train, validation and test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPPcrxFQHS-r",
        "outputId": "cbe50baf-afea-4d6f-f470-8713f6c05682"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://cs231n.stanford.edu/tiny-imagenet-200.zip to /root/.torchvision/tinyimagenet/tiny-imagenet-200.zip\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 248M/248M [00:15<00:00, 16.0MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting /root/.torchvision/tinyimagenet/tiny-imagenet-200.zip to /root/.torchvision/tinyimagenet\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:About to delete /root/.torchvision/tinyimagenet/tiny-imagenet-200/val/images\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset downloaded!\n",
            "['n01443537', 'n01629819', 'n01641577', 'n01644900', 'n01698640', 'n01742172', 'n01768244', 'n01770393', 'n01774384', 'n01774750', 'n01784675', 'n01855672', 'n01882714', 'n01910747', 'n01917289', 'n01944390', 'n01945685', 'n01950731', 'n01983481', 'n01984695', 'n02002724', 'n02056570', 'n02058221', 'n02074367', 'n02085620', 'n02094433', 'n02099601', 'n02099712', 'n02106662', 'n02113799', 'n02123045', 'n02123394', 'n02124075', 'n02125311', 'n02129165', 'n02132136', 'n02165456', 'n02190166', 'n02206856', 'n02226429', 'n02231487', 'n02233338', 'n02236044', 'n02268443', 'n02279972', 'n02281406', 'n02321529', 'n02364673', 'n02395406', 'n02403003', 'n02410509', 'n02415577', 'n02423022', 'n02437312', 'n02480495', 'n02481823', 'n02486410', 'n02504458', 'n02509815', 'n02666196', 'n02669723', 'n02699494', 'n02730930', 'n02769748', 'n02788148', 'n02791270', 'n02793495', 'n02795169', 'n02802426', 'n02808440', 'n02814533', 'n02814860', 'n02815834', 'n02823428', 'n02837789', 'n02841315', 'n02843684', 'n02883205', 'n02892201', 'n02906734', 'n02909870', 'n02917067', 'n02927161', 'n02948072', 'n02950826', 'n02963159', 'n02977058', 'n02988304', 'n02999410', 'n03014705', 'n03026506', 'n03042490', 'n03085013', 'n03089624', 'n03100240', 'n03126707', 'n03160309', 'n03179701', 'n03201208', 'n03250847', 'n03255030', 'n03355925', 'n03388043', 'n03393912', 'n03400231', 'n03404251', 'n03424325', 'n03444034', 'n03447447', 'n03544143', 'n03584254', 'n03599486', 'n03617480', 'n03637318', 'n03649909', 'n03662601', 'n03670208', 'n03706229', 'n03733131', 'n03763968', 'n03770439', 'n03796401', 'n03804744', 'n03814639', 'n03837869', 'n03838899', 'n03854065', 'n03891332', 'n03902125', 'n03930313', 'n03937543', 'n03970156', 'n03976657', 'n03977966', 'n03980874', 'n03983396', 'n03992509', 'n04008634', 'n04023962', 'n04067472', 'n04070727', 'n04074963', 'n04099969', 'n04118538', 'n04133789', 'n04146614', 'n04149813', 'n04179913', 'n04251144', 'n04254777', 'n04259630', 'n04265275', 'n04275548', 'n04285008', 'n04311004', 'n04328186', 'n04356056', 'n04366367', 'n04371430', 'n04376876', 'n04398044', 'n04399382', 'n04417672', 'n04456115', 'n04465501', 'n04486054', 'n04487081', 'n04501370', 'n04507155', 'n04532106', 'n04532670', 'n04540053', 'n04560804', 'n04562935', 'n04596742', 'n04597913', 'n06596364', 'n07579787', 'n07583066', 'n07614500', 'n07615774', 'n07695742', 'n07711569', 'n07715103', 'n07720875', 'n07734744', 'n07747607', 'n07749582', 'n07753592', 'n07768694', 'n07871810', 'n07873807', 'n07875152', 'n07920052', 'n09193705', 'n09246464', 'n09256479', 'n09332890', 'n09428293', 'n12267677']\n"
          ]
        }
      ],
      "source": [
        "datasets = [\"tinyimagenet\", \"cifar10\"]\n",
        "dataset_idx = 0\n",
        "dataset_name = datasets[dataset_idx]\n",
        "use_subset = False\n",
        "subset_classes = 20\n",
        "\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(img_size, padding=8),\n",
        "    transforms.Resize(img_size),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=TinyImageNet.mean, std=TinyImageNet.std),\n",
        "])\n",
        "\n",
        "transform_validation = transforms.Compose([\n",
        "    transforms.Resize(img_size),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=TinyImageNet.mean, std=TinyImageNet.std),\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Prepare and load TinyImageNet dataset\n",
        "if (dataset_idx == 0):\n",
        "    trainset = TinyImageNet(Path(\"~/.torchvision/tinyimagenet/\"),split=\"train\",imagenet_idx=False, transform=transform_train)\n",
        "    validationset = TinyImageNet(Path(\"~/.torchvision/tinyimagenet/\"),split=\"val\",imagenet_idx=False, transform=transform_validation)\n",
        "\n",
        "if (dataset_idx == 1):\n",
        "    # Prepare/download CIFAR10 dataset\n",
        "    trainset = torchvision.datasets.CIFAR10(root=dataset_path, train=True, download=True, transform=transform_train)\n",
        "    validationset = torchvision.datasets.CIFAR10(root=dataset_path, train=False, download=True, transform=transform_validation)\n",
        "\n",
        "print(\"Dataset downloaded!\")\n",
        "# Only select 20 classes from tinyimagenet.\n",
        "if use_subset:\n",
        "    print(\"Using subset of {} classes\".format(subset_classes))\n",
        "     # Select 20 random classes\n",
        "    selected_classes = list(range(subset_classes))\n",
        "    class_to_idx = {cls: idx for idx, cls in enumerate(selected_classes)}\n",
        "\n",
        "\n",
        "    # Filter the dataset to include only the selected classes\n",
        "    train_subset_indices = [i for i, (_, label) in enumerate(validationset) if label in selected_classes]\n",
        "    val_subset = data.Subset(validationset, train_subset_indices)\n",
        "    val_subset_indices = [i for i, (_, label) in enumerate(trainset) if label in selected_classes]\n",
        "    train_subset = data.Subset(trainset, val_subset_indices)\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(train_subset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "    print(\"trainloader created successfully.\")\n",
        "    dataset_size = len(val_subset)\n",
        "    validation_size = int(0.95 * dataset_size)\n",
        "    test_size = dataset_size - validation_size\n",
        "\n",
        "    val_subset, test_subset = data.random_split(val_subset, [validation_size, test_size])\n",
        "\n",
        "    validation_loader = torch.utils.data.DataLoader(val_subset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
        "    test_loader = torch.utils.data.DataLoader(test_subset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
        "    classes = class_to_idx\n",
        "    print(len(np.unique(val_subset.indices)))\n",
        "    print(len(np.unique(train_subset.indices)))\n",
        "\n",
        "else:\n",
        "    dataset_size = len(validationset)\n",
        "    validation_size = int(0.95 * dataset_size)\n",
        "    test_size = dataset_size - validation_size\n",
        "    validationset, testset = data.random_split(validationset, [validation_size, test_size])\n",
        "    train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "    validation_loader = torch.utils.data.DataLoader(validationset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
        "    test_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
        "    classes = trainset.classes\n",
        "\n",
        "# classes = trainset.classes\n",
        "\n",
        "print(classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4JC4EFqtfK5"
      },
      "source": [
        "# Agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YL2DwKZ1Mdkr"
      },
      "source": [
        "### Functions for training and validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9IYQ9yHAUwe"
      },
      "source": [
        "### Initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "TaR2dDv2MQaV"
      },
      "outputs": [],
      "source": [
        "buffer_batch_size = 8\n",
        "buffer_size = 64\n",
        "\n",
        "gamma = 0.95\n",
        "\n",
        "eps_start = 1\n",
        "eps_end = 0.01\n",
        "eps = eps_start\n",
        "eps_decay = 20000\n",
        "\n",
        "lr = 0.01\n",
        "\n",
        "tau = 0.1\n",
        "update_every = 2\n",
        "\n",
        "get_reward_every = 10\n",
        "\n",
        "pretrained = False # Pretrained with CIFAR10 weights, that is.\n",
        "\n",
        "max_reward = 10\n",
        "alpha = 0.2 # Where alpha defines weight of loss reward, and 1-alpha defines weight of patch (time) reward\n",
        "# loss_weight = max_reward*(alpha)  # TODO THIS ONE TOO\n",
        "# time_weight = max_reward*(1-alpha) # TODO PLAY WITH THESE VALUES A LOT\n",
        "loss_weight = alpha\n",
        "time_weight = 1-alpha\n",
        "\n",
        "# Input image to DQN agent's  Q-network\n",
        "# for CIFAR, lowres=16, fullres=32\n",
        "# For TinyImageNet, halfres = 32, fullres = 64\n",
        "dqn_img_w = 32\n",
        "dqn_input_channels = 3\n",
        "dqn_input_size = dqn_img_w*dqn_img_w*dqn_input_channels # input to DQN (mlp type)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vl8vY8iKrKbW",
        "outputId": "a006f5e7-e1f7-40c0-c6d7-d5469e24b1c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "64\n"
          ]
        }
      ],
      "source": [
        "# This is the number of patches along the width/height of the square image.\n",
        "# TODO refactor...img_size is defined WAY up in the notebook, right before dataset loader initialization\n",
        "patch_width = 8\n",
        "# patch_size = int(img_size/patch_width)\n",
        "patch_size = patch_width # This is what you get when you work with someone else's code and don't want to rewrite everything.\n",
        "\n",
        "\n",
        "total_patches = int((img_size/patch_width)**2)\n",
        "print(total_patches)\n",
        "n_patch_selected = int(total_patches*(40/64)) # From the paper\n",
        "\n",
        "\n",
        "att_dim = 128\n",
        "\n",
        "epochs = 20\n",
        "learning_rate = 0.001\n",
        "\n",
        "ViTnet = SimpleAgentViT(\n",
        "    image_size = img_size,\n",
        "    patch_size = patch_size,\n",
        "    num_classes = len(classes),\n",
        "    dim = att_dim,\n",
        "    depth = 6,\n",
        "    heads = 16,\n",
        "    mlp_dim = 512\n",
        ")\n",
        "\n",
        "# Sposta il modello sulla GPU (se disponibile)\n",
        "ViTnet.to(device)\n",
        "\n",
        "# definiamo l'ottimizzatore\n",
        "optimizer = optim.Adam(ViTnet.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "_ernM9pqoxbd"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "#env = ViTEnv(ViTnet, total_patches, optimizer, loss_weight, time_weight, device, n_patch_selected)\n",
        "env = ViTEnv(ViTnet, total_patches, optimizer, loss_weight, time_weight, device, n_patch_selected, total_epochs=epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRn2Tplb90tO",
        "outputId": "41f4a30b-3136-4e9e-a179-097a5081f65f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ConvNet created! Value of pretrained: False\n",
            "ConvNet created! Value of pretrained: False\n"
          ]
        }
      ],
      "source": [
        "model = TrainingTestingAgent(epochs = epochs,\n",
        "                             model = ViTnet,\n",
        "                             get_reward_every = get_reward_every,\n",
        "                             buffer_batch_size = buffer_batch_size,\n",
        "                             batch_size = batch_size,\n",
        "                             env = env,\n",
        "                             att_dim = att_dim,\n",
        "                             n_patches = total_patches,\n",
        "                             buffer_size = buffer_size,\n",
        "                             gamma = gamma,\n",
        "                             tau = tau,\n",
        "                             update_every = update_every,\n",
        "                             lr = lr,\n",
        "                             eps_end = eps_end,\n",
        "                             eps_start = eps_start,\n",
        "                             eps_decay = eps_decay,\n",
        "                             train_loader = train_loader,\n",
        "                             validation_loader = validation_loader,\n",
        "                             device = device,\n",
        "                             dqn_input_size=dqn_input_size,\n",
        "                             pretrained=pretrained)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7P_6HzWGn8G",
        "outputId": "53ccab97-f50a-494b-d826-2f819cb4a614"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ConvNet created! Value of pretrained: False\n",
            "ConvNet created! Value of pretrained: False\n"
          ]
        }
      ],
      "source": [
        "model = TrainingTestingAgent(epochs = epochs,\n",
        "                             model = ViTnet,\n",
        "                             get_reward_every = get_reward_every,\n",
        "                             buffer_batch_size = buffer_batch_size,\n",
        "                             batch_size = batch_size,\n",
        "                             env = env,\n",
        "                             att_dim = att_dim,\n",
        "                             n_patches = total_patches,\n",
        "                             buffer_size = buffer_size,\n",
        "                             gamma = gamma,\n",
        "                             tau = tau,\n",
        "                             update_every = update_every,\n",
        "                             lr = lr,\n",
        "                             eps_end = eps_end,\n",
        "                             eps_start = eps_start,\n",
        "                             eps_decay = eps_decay,\n",
        "                             train_loader = train_loader,\n",
        "                             validation_loader = validation_loader,\n",
        "                             device = device,\n",
        "                             dqn_input_size=dqn_input_size,\n",
        "                             pretrained=pretrained)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkkBVX1GrKbX"
      },
      "source": [
        "### Train SimpleViT (no patch selection)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "8Vl0fUiTrKbY"
      },
      "outputs": [],
      "source": [
        "# Training loop for SimpleViT\n",
        "def train_simple_vit(model, train_loader, criterion, optimizer, device, num_epochs):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader)}\")\n",
        "\n",
        "\n",
        "trainSimple = False\n",
        "\n",
        "if trainSimple:\n",
        "\n",
        "    # Define the device\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Initialize the SimpleViT model, criterion, and optimizer\n",
        "    model = SimpleViT(\n",
        "        image_size = img_size,\n",
        "        patch_size = patch_size,\n",
        "        num_classes = len(classes),\n",
        "        dim = att_dim,\n",
        "        depth = 6,\n",
        "        heads = 16,\n",
        "        mlp_dim = 512).to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    train_simple_vit(model, train_loader, criterion, optimizer, device, num_epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Visualize the patch selection and attention scores for the untrained models.\n",
        "## Use functions defined in viz.py\n",
        "# Select a random set of 5 images from the dataset\n",
        "num_images = 5\n",
        "random_indices = np.random.choice(len(trainset), num_images, replace=False)\n",
        "random_images = [trainset[i][0] for i in random_indices]\n",
        "\n",
        "# Visualize the patch selection and attention scores\n",
        "for img in random_images:\n",
        "    visualize_selected_patches(img, ViTnet, device)\n",
        "    visualize_attention_scores(img, ViTnet, device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38RJhPQMAaXd"
      },
      "source": [
        "### Train AgentViT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g81PySpAHgc5",
        "outputId": "816f6100-3fe5-4c0b-ecdf-7acd898ae45d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1/20\n",
            "  Patch list: [0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0]\n",
            "  Selected Patches: 29\n",
            "  loss_reward: 1.0\n",
            "  patches_reward: -0.4583333333333333\n",
            "  Epsilon: 0.9995546002224661,   Reward: -0.13124999999999998\n",
            "  Patch list: [0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1]\n",
            "  Selected Patches: 29\n",
            "  loss_reward: 1.0290664582785751\n",
            "  patches_reward: -0.4583333333333333\n",
            "  Epsilon: 0.9990599465960667,   Reward: -0.12427405001314196\n",
            "  Patch list: [1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0]\n",
            "  Selected Patches: 35\n",
            "  loss_reward: 1.0126830615686864\n",
            "  patches_reward: -0.20833333333333334\n",
            "  Epsilon: 0.9985655402346592,   Reward: 0.07429393477648477\n",
            "  Patch list: [1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0]\n",
            "  Selected Patches: 33\n",
            "  loss_reward: 1.0168249556614488\n",
            "  patches_reward: -0.2916666666666667\n",
            "  Epsilon: 0.9980713810146418,   Reward: 0.007787989358747721\n",
            "  Patch list: [1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0]\n",
            "  Selected Patches: 31\n",
            "  loss_reward: 1.0353805074679734\n",
            "  patches_reward: -0.375\n",
            "  Epsilon: 0.9975774688124749,   Reward: -0.055258678207686346\n",
            "  Patch list: [1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1]\n",
            "  Selected Patches: 29\n",
            "  loss_reward: 1.0312298590646782\n",
            "  patches_reward: -0.4583333333333333\n",
            "  Epsilon: 0.9970838035046803,   Reward: -0.12375483382447719\n",
            "  Patch list: [0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1]\n",
            "  Selected Patches: 30\n",
            "  loss_reward: 1.0220713464813695\n",
            "  patches_reward: -0.4166666666666667\n",
            "  Epsilon: 0.9965903849678418,   Reward: -0.09220287684447129\n",
            "  Patch list: [0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0]\n",
            "  Selected Patches: 32\n",
            "  loss_reward: 1.0505078508553336\n",
            "  patches_reward: -0.3333333333333333\n",
            "  Epsilon: 0.9960972130786045,   Reward: -0.01787811579471993\n",
            "  Patch list: [0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0]\n",
            "  Selected Patches: 35\n",
            "  loss_reward: 1.0354480926952896\n",
            "  patches_reward: -0.20833333333333334\n",
            "  Epsilon: 0.9956042877136758,   Reward: 0.07975754224686954\n",
            "  Patch list: [0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1]\n",
            "  Selected Patches: 32\n",
            "  loss_reward: 1.0238431455083143\n",
            "  patches_reward: -0.3333333333333333\n",
            "  Epsilon: 0.995111608749824,   Reward: -0.024277645078004534\n",
            "  Patch list: [1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1]\n",
            "  Selected Patches: 29\n",
            "  loss_reward: 1.0335535361250165\n",
            "  patches_reward: -0.4583333333333333\n",
            "  Epsilon: 0.9946191760638795,   Reward: -0.12319715132999601\n",
            "  Patch list: [1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0]\n",
            "  Selected Patches: 34\n",
            "  loss_reward: 1.0295228795156548\n",
            "  patches_reward: -0.25\n",
            "  Epsilon: 0.9941269895327343,   Reward: 0.04458549108375717\n",
            "  Patch list: [1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0]\n",
            "  Selected Patches: 29\n",
            "  loss_reward: 1.0335214095278704\n",
            "  patches_reward: -0.4583333333333333\n",
            "  Epsilon: 0.9936350490333415,   Reward: -0.12320486171331108\n",
            "  Patch list: [0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0]\n",
            "  Selected Patches: 29\n",
            "  loss_reward: 1.0760480222686055\n",
            "  patches_reward: -0.4583333333333333\n",
            "  Epsilon: 0.9931433544427162,   Reward: -0.11299847465553464\n",
            "  Patch list: [0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1]\n",
            "  Selected Patches: 31\n",
            "  loss_reward: 1.0544080315243922\n",
            "  patches_reward: -0.375\n",
            "  Epsilon: 0.9926519056379346,   Reward: -0.05069207243414586\n",
            "  Patch list: [1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0]\n",
            "  Selected Patches: 32\n",
            "  loss_reward: 1.0349725692051412\n",
            "  patches_reward: -0.3333333333333333\n",
            "  Epsilon: 0.9921607024961344,   Reward: -0.02160658339076607\n",
            "  Patch list: [1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]\n",
            "  Selected Patches: 31\n",
            "  loss_reward: 1.0617495058837023\n",
            "  patches_reward: -0.375\n",
            "  Epsilon: 0.991669744894515,   Reward: -0.04893011858791141\n",
            "  Patch list: [1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0]\n",
            "  Selected Patches: 31\n",
            "  loss_reward: 1.055967624043996\n",
            "  patches_reward: -0.375\n",
            "  Epsilon: 0.991179032710337,   Reward: -0.05031777022944095\n",
            "  Patch list: [1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0]\n",
            "  Selected Patches: 33\n",
            "  loss_reward: 1.0453639511049722\n",
            "  patches_reward: -0.2916666666666667\n",
            "  Epsilon: 0.9906885658209222,   Reward: 0.014637348265193334\n",
            "  Patch list: [1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0]\n",
            "  Selected Patches: 31\n",
            "  loss_reward: 1.0506922736541817\n",
            "  patches_reward: -0.375\n",
            "  Epsilon: 0.9901983441036541,   Reward: -0.051583854322996336\n",
            "  Patch list: [1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0]\n",
            "  Selected Patches: 30\n",
            "  loss_reward: 1.0882471781588448\n",
            "  patches_reward: -0.4166666666666667\n",
            "  Epsilon: 0.989708367435977,   Reward: -0.07632067724187724\n",
            "  Patch list: [1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0]\n",
            "  Selected Patches: 29\n",
            "  loss_reward: 1.0244546370378267\n",
            "  patches_reward: -0.4583333333333333\n",
            "  Epsilon: 0.9892186356953969,   Reward: -0.12538088711092157\n",
            "  Patch list: [1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0]\n",
            "  Selected Patches: 32\n",
            "  loss_reward: 1.0749634102829848\n",
            "  patches_reward: -0.3333333333333333\n",
            "  Epsilon: 0.9887291487594808,   Reward: -0.012008781532083623\n",
            "  Patch list: [1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0]\n",
            "  Selected Patches: 32\n",
            "  loss_reward: 1.0591886334681089\n",
            "  patches_reward: -0.3333333333333333\n",
            "  Epsilon: 0.988239906505857,   Reward: -0.015794727967653854\n",
            "  Patch list: [1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0]\n",
            "  Selected Patches: 32\n",
            "  loss_reward: 1.0767369904227915\n",
            "  patches_reward: -0.3333333333333333\n",
            "  Epsilon: 0.987750908812215,   Reward: -0.011583122298530035\n",
            "  Patch list: [1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0]\n",
            "  Selected Patches: 33\n",
            "  loss_reward: 1.101980043801919\n",
            "  patches_reward: -0.2916666666666667\n",
            "  Epsilon: 0.9872621555563053,   Reward: 0.028225210512460547\n",
            "  Patch list: [1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0]\n",
            "  Selected Patches: 30\n",
            "  loss_reward: 1.0435383916927476\n",
            "  patches_reward: -0.4166666666666667\n",
            "  Epsilon: 0.9867736466159395,   Reward: -0.08705078599374055\n",
            "  Patch list: [0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0]\n",
            "  Selected Patches: 35\n",
            "  loss_reward: 1.111559865201098\n",
            "  patches_reward: -0.20833333333333334\n",
            "  Epsilon: 0.9862853818689904,   Reward: 0.09802436764826356\n",
            "  Patch list: [1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0]\n",
            "  Selected Patches: 38\n",
            "  loss_reward: 1.065732841182932\n",
            "  patches_reward: -0.08333333333333333\n",
            "  Epsilon: 0.9857973611933918,   Reward: 0.18827588188390376\n",
            "  Patch list: [1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0]\n",
            "  Selected Patches: 36\n",
            "  loss_reward: 1.10776046125112\n",
            "  patches_reward: -0.16666666666666666\n",
            "  Epsilon: 0.9853095844671388,   Reward: 0.13086251070026883\n",
            "  Patch list: [1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0]\n",
            "  Selected Patches: 34\n",
            "  loss_reward: 1.0774962526079446\n",
            "  patches_reward: -0.25\n",
            "  Epsilon: 0.9848220515682868,   Reward: 0.05609910062590673\n",
            "  Patch list: [0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0]\n",
            "  Selected Patches: 32\n",
            "  loss_reward: 1.0807761882617894\n",
            "  patches_reward: -0.3333333333333333\n",
            "  Epsilon: 0.9843347623749529,   Reward: -0.010613714817170494\n",
            "  Patch list: [1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0]\n",
            "  Selected Patches: 33\n",
            "  loss_reward: 1.0633468388333\n",
            "  patches_reward: -0.2916666666666667\n",
            "  Epsilon: 0.9838477167653146,   Reward: 0.018953241319992015\n",
            "  Patch list: [0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0]\n",
            "  Selected Patches: 33\n",
            "  loss_reward: 1.103238047486421\n",
            "  patches_reward: -0.2916666666666667\n",
            "  Epsilon: 0.9833609146176105,   Reward: 0.02852713139674104\n",
            "  Patch list: [0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1]\n",
            "  Selected Patches: 32\n",
            "  loss_reward: 1.109755229720831\n",
            "  patches_reward: -0.3333333333333333\n",
            "  Epsilon: 0.9828743558101403,   Reward: -0.0036587448670005185\n",
            "  Patch list: [1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1]\n",
            "  Selected Patches: 36\n",
            "  loss_reward: 1.1178302514165268\n",
            "  patches_reward: -0.16666666666666666\n",
            "  Epsilon: 0.982388040221264,   Reward: 0.13327926033996645\n",
            "  Patch list: [0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1]\n",
            "  Selected Patches: 32\n",
            "  loss_reward: 1.0971155032349704\n",
            "  patches_reward: -0.3333333333333333\n",
            "  Epsilon: 0.9819019677294029,   Reward: -0.006692279223607045\n",
            "  Patch list: [0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0]\n",
            "  Selected Patches: 27\n",
            "  loss_reward: 1.1140539544153651\n",
            "  patches_reward: -0.5416666666666666\n",
            "  Epsilon: 0.9814161382130386,   Reward: -0.1713770509403123\n",
            "  Patch list: [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "  Selected Patches: 33\n",
            "  loss_reward: 1.0823791607295636\n",
            "  patches_reward: -0.2916666666666667\n",
            "  Epsilon: 0.9809305515507141,   Reward: 0.023520998575095292\n",
            "  Patch list: [0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0]\n",
            "  Selected Patches: 32\n",
            "  loss_reward: 1.0956156079965793\n",
            "  patches_reward: -0.3333333333333333\n",
            "  Epsilon: 0.9804452076210326,   Reward: -0.007052254080820941\n",
            "  Patch list: [1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0]\n",
            "  Selected Patches: 30\n",
            "  loss_reward: 1.0845513474035768\n",
            "  patches_reward: -0.4166666666666667\n",
            "  Epsilon: 0.9799601063026578,   Reward: -0.07720767662314154\n",
            "  Patch list: [0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0]\n",
            "  Selected Patches: 29\n",
            "  loss_reward: 1.0955494795864158\n",
            "  patches_reward: -0.4583333333333333\n",
            "  Epsilon: 0.9794752474743148,   Reward: -0.10831812489926018\n",
            "  Patch list: [0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1]\n",
            "  Selected Patches: 33\n",
            "  loss_reward: 1.1148503873327646\n",
            "  patches_reward: -0.2916666666666667\n",
            "  Epsilon: 0.9789906310147887,   Reward: 0.03131409295986351\n",
            "  Patch list: [0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "  Selected Patches: 29\n",
            "  loss_reward: 1.0932455088874364\n",
            "  patches_reward: -0.4583333333333333\n",
            "  Epsilon: 0.9785062568029255,   Reward: -0.10887107786701522\n",
            "  Patch list: [1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0]\n",
            "  Selected Patches: 30\n",
            "  loss_reward: 1.1216912102521512\n",
            "  patches_reward: -0.4166666666666667\n",
            "  Epsilon: 0.9780221247176314,   Reward: -0.06829410953948367\n",
            "  Patch list: [0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0]\n",
            "  Selected Patches: 30\n",
            "  loss_reward: 1.1080472542926993\n",
            "  patches_reward: -0.4166666666666667\n",
            "  Epsilon: 0.9775382346378735,   Reward: -0.07156865896975212\n",
            "  Patch list: [0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1]\n",
            "  Selected Patches: 31\n",
            "  loss_reward: 1.1266583057108042\n",
            "  patches_reward: -0.375\n",
            "  Epsilon: 0.9770545864426795,   Reward: -0.03335200662940696\n",
            "  Patch list: [1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0]\n",
            "  Selected Patches: 31\n",
            "  loss_reward: 1.0815651418777972\n",
            "  patches_reward: -0.375\n",
            "  Epsilon: 0.976571180011137,   Reward: -0.044174365949328664\n",
            "  Patch list: [1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0]\n",
            "  Selected Patches: 34\n",
            "  loss_reward: 1.167654427904538\n",
            "  patches_reward: -0.25\n",
            "  Epsilon: 0.9760880152223944,   Reward: 0.07773706269708919\n",
            "  Patch list: [1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1]\n",
            "  Selected Patches: 31\n",
            "  loss_reward: 1.1281121494565327\n",
            "  patches_reward: -0.375\n",
            "  Epsilon: 0.9756050919556609,   Reward: -0.033003084130432125\n",
            "  Patch list: [0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0]\n",
            "  Selected Patches: 30\n",
            "  loss_reward: 1.1120910745253638\n",
            "  patches_reward: -0.4166666666666667\n",
            "  Epsilon: 0.9751224100902053,   Reward: -0.07059814211391263\n",
            "  Patch list: [0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0]\n",
            "  Selected Patches: 31\n",
            "  loss_reward: 1.118174112660777\n",
            "  patches_reward: -0.375\n",
            "  Epsilon: 0.9746399695053573,   Reward: -0.03538821296141348\n",
            "  Patch list: [0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0]\n",
            "  Selected Patches: 29\n",
            "  loss_reward: 1.0900877591458522\n",
            "  patches_reward: -0.4583333333333333\n",
            "  Epsilon: 0.9741577700805065,   Reward: -0.10962893780499544\n",
            "  Patch list: [1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0]\n",
            "  Selected Patches: 36\n",
            "  loss_reward: 1.1127362861783885\n",
            "  patches_reward: -0.16666666666666666\n",
            "  Epsilon: 0.9736758116951035,   Reward: 0.13205670868281327\n",
            "  Patch list: [0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1]\n",
            "  Selected Patches: 34\n",
            "  loss_reward: 1.099050156388192\n",
            "  patches_reward: -0.25\n",
            "  Epsilon: 0.9731940942286583,   Reward: 0.061272037533166124\n",
            "  Patch list: [0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1]\n",
            "  Selected Patches: 33\n",
            "  loss_reward: 1.1336434018998098\n",
            "  patches_reward: -0.2916666666666667\n",
            "  Epsilon: 0.9727126175607418,   Reward: 0.03582441645595438\n",
            "  Patch list: [1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0]\n",
            "  Selected Patches: 32\n",
            "  loss_reward: 1.109119469040289\n",
            "  patches_reward: -0.3333333333333333\n",
            "  Epsilon: 0.9722313815709845,   Reward: -0.00381132743033058\n",
            "  Patch list: [1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0]\n",
            "  Selected Patches: 30\n",
            "  loss_reward: 1.1543438584463317\n",
            "  patches_reward: -0.4166666666666667\n",
            "  Epsilon: 0.9717503861390778,   Reward: -0.06045747397288037\n",
            "  Patch list: [1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1]\n",
            "  Selected Patches: 33\n",
            "  loss_reward: 1.1095772900505176\n",
            "  patches_reward: -0.2916666666666667\n",
            "  Epsilon: 0.9712696311447725,   Reward: 0.030048549612124248\n",
            "  Patch list: [1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0]\n",
            "  Selected Patches: 33\n",
            "  loss_reward: 1.1274077751796883\n",
            "  patches_reward: -0.2916666666666667\n",
            "  Epsilon: 0.9707891164678801,   Reward: 0.03432786604312518\n",
            "  Patch list: [0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0]\n",
            "  Selected Patches: 31\n",
            "  loss_reward: 1.1182361114674004\n",
            "  patches_reward: -0.375\n",
            "  Epsilon: 0.9703088419882718,   Reward: -0.03537333324782388\n",
            "  Patch list: [0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0]\n",
            "  Selected Patches: 30\n",
            "  loss_reward: 1.1819857646945038\n",
            "  patches_reward: -0.4166666666666667\n",
            "  Epsilon: 0.969828807585879,   Reward: -0.05382341647331906\n",
            "  Patch list: [0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1]\n",
            "  Selected Patches: 32\n",
            "  loss_reward: 1.1689137758296146\n",
            "  patches_reward: -0.3333333333333333\n",
            "  Epsilon: 0.969349013140693,   Reward: 0.010539306199107534\n",
            "  Patch list: [1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0]\n",
            "  Selected Patches: 30\n",
            "  loss_reward: 1.1343344409472793\n",
            "  patches_reward: -0.4166666666666667\n",
            "  Epsilon: 0.9688694585327654,   Reward: -0.06525973417265296\n",
            "  Patch list: [0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1]\n",
            "  Selected Patches: 32\n",
            "  loss_reward: 1.1140204394626332\n",
            "  patches_reward: -0.3333333333333333\n",
            "  Epsilon: 0.9683901436422073,   Reward: -0.002635094528967985\n",
            "  Patch list: [0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1]\n",
            "  Selected Patches: 28\n",
            "  loss_reward: 1.0919637605491619\n",
            "  patches_reward: -0.5\n",
            "  Epsilon: 0.9679110683491903,   Reward: -0.14292869746820114\n",
            "  Patch list: [0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1]\n",
            "  Selected Patches: 35\n",
            "  loss_reward: 1.1279958417942062\n",
            "  patches_reward: -0.20833333333333334\n",
            "  Epsilon: 0.9674322325339452,   Reward: 0.10196900203060955\n",
            "  Patch list: [0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0]\n",
            "  Selected Patches: 30\n",
            "  loss_reward: 1.1238111052591353\n",
            "  patches_reward: -0.4166666666666667\n",
            "  Epsilon: 0.9669536360767632,   Reward: -0.06778533473780751\n",
            "  Patch list: [1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1]\n",
            "  Selected Patches: 30\n",
            "  loss_reward: 1.1041703606475504\n",
            "  patches_reward: -0.4166666666666667\n",
            "  Epsilon: 0.9664752788579953,   Reward: -0.07249911344458787\n",
            "  Patch list: [1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0]\n",
            "  Selected Patches: 28\n",
            "  loss_reward: 1.0949122376243812\n",
            "  patches_reward: -0.5\n",
            "  Epsilon: 0.9659971607580522,   Reward: -0.14222106297014847\n",
            "  Patch list: [1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1]\n",
            "  Selected Patches: 31\n",
            "  loss_reward: 1.127786732225173\n",
            "  patches_reward: -0.375\n",
            "  Epsilon: 0.9655192816574041,   Reward: -0.03308118426595846\n",
            "  Patch list: [0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]\n",
            "  Selected Patches: 30\n",
            "  loss_reward: 1.1340387589777279\n",
            "  patches_reward: -0.4166666666666667\n",
            "  Epsilon: 0.9650416414365814,   Reward: -0.06533069784534529\n",
            "  Patch list: [1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n",
            "  Selected Patches: 32\n",
            "  loss_reward: 1.1538017053149918\n",
            "  patches_reward: -0.3333333333333333\n",
            "  Epsilon: 0.9645642399761742,   Reward: 0.006912409275598053\n",
            "  Patch list: [0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0]\n",
            "  Selected Patches: 33\n",
            "  loss_reward: 1.1631047416675577\n",
            "  patches_reward: -0.2916666666666667\n",
            "  Epsilon: 0.9640870771568318,   Reward: 0.042895138000213856\n",
            "  Patch list: [1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0]\n",
            "  Selected Patches: 32\n",
            "  loss_reward: 1.1253675156374874\n",
            "  patches_reward: -0.3333333333333333\n",
            "  Epsilon: 0.9636101528592638,   Reward: 8.8203752997007e-05\n",
            "  Patch list: [1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0]\n",
            "  Selected Patches: 32\n",
            "  loss_reward: 1.1232670477458115\n",
            "  patches_reward: -0.3333333333333333\n",
            "  Epsilon: 0.9631334669642387,   Reward: -0.00041590854100520547\n",
            "  Patch list: [0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0]\n",
            "  Selected Patches: 27\n",
            "  loss_reward: 1.132730316749951\n",
            "  patches_reward: -0.5416666666666666\n",
            "  Epsilon: 0.9626570193525855,   Reward: -0.1668947239800117\n",
            "  Patch list: [0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1]\n",
            "  Selected Patches: 33\n",
            "  loss_reward: 1.1332529599844916\n",
            "  patches_reward: -0.2916666666666667\n",
            "  Epsilon: 0.9621808099051922,   Reward: 0.03573071039627798\n",
            "\n",
            "Inizio Testing\n",
            "\n",
            "\n",
            "Average test loss: 4.5694  Accuracy:  629/ 9500 (6.62%)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch time: 88.30744934082031\n",
            "########################################\n",
            "########################################\n",
            "Episode End\n",
            "########################################\n",
            "########################################\n",
            "Epoch: 2/20\n",
            "  Patch list: [0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0]\n",
            "  Selected Patches: 32\n",
            "  loss_reward: 1.1200754826770007\n",
            "  patches_reward: -0.3333333333333333\n",
            "  Epsilon: 0.9616096727775215,   Reward: 0.04028780181622693\n",
            "  Patch list: [0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1]\n",
            "  Selected Patches: 31\n",
            "  loss_reward: 1.1109225930620854\n",
            "  patches_reward: -0.375\n",
            "  Epsilon: 0.961133986872519,   Reward: 0.0035583260573839315\n",
            "  Patch list: [0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1]\n",
            "  Selected Patches: 37\n",
            "  loss_reward: 1.1503483465680822\n",
            "  patches_reward: -0.125\n",
            "  Epsilon: 0.9606585387510184,   Reward: 0.21959753703906304\n",
            "  Patch list: [1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0]\n",
            "  Selected Patches: 32\n",
            "  loss_reward: 1.157553288339356\n",
            "  patches_reward: -0.3333333333333333\n",
            "  Epsilon: 0.9601833282941572,   Reward: 0.05078158740168637\n",
            "  Patch list: [1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1]\n",
            "  Selected Patches: 30\n",
            "  loss_reward: 1.1250346488094223\n",
            "  patches_reward: -0.4166666666666667\n",
            "  Epsilon: 0.9597083553831333,   Reward: -0.0266569650000284\n",
            "  Patch list: [0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0]\n",
            "  Selected Patches: 32\n",
            "  loss_reward: 1.1668487911127625\n",
            "  patches_reward: -0.3333333333333333\n",
            "  Epsilon: 0.959233619899203,   Reward: 0.05338432817824024\n",
            "  Patch list: [1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0]\n",
            "  Selected Patches: 36\n",
            "  loss_reward: 1.1525363001858377\n",
            "  patches_reward: -0.16666666666666666\n",
            "  Epsilon: 0.9587591217236826,   Reward: 0.18604349738536796\n",
            "  Patch list: [1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0]\n",
            "  Selected Patches: 32\n",
            "  loss_reward: 1.171307543194554\n",
            "  patches_reward: -0.3333333333333333\n",
            "  Epsilon: 0.9582848607379476,   Reward: 0.054632778761141865\n",
            "  Patch list: [1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]\n",
            "  Selected Patches: 32\n",
            "  loss_reward: 1.1458950305238413\n",
            "  patches_reward: -0.3333333333333333\n",
            "  Epsilon: 0.9578108368234328,   Reward: 0.047517275213342314\n",
            "  Patch list: [0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1]\n",
            "  Selected Patches: 32\n",
            "  loss_reward: 1.1743145090255644\n",
            "  patches_reward: -0.3333333333333333\n",
            "  Epsilon: 0.9573370498616322,   Reward: 0.055474729193824734\n",
            "  Patch list: [0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1]\n",
            "  Selected Patches: 31\n",
            "  loss_reward: 1.1535408546609265\n",
            "  patches_reward: -0.375\n",
            "  Epsilon: 0.9568634997340988,   Reward: 0.015491439305059473\n",
            "  Patch list: [1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0]\n",
            "  Selected Patches: 26\n",
            "  loss_reward: 1.185585014888142\n",
            "  patches_reward: -0.5833333333333334\n",
            "  Epsilon: 0.9563901863224453,   Reward: -0.14636952916465357\n",
            "  Patch list: [0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1]\n",
            "  Selected Patches: 31\n",
            "  loss_reward: 1.177622205365511\n",
            "  patches_reward: -0.375\n",
            "  Epsilon: 0.9559171095083434,   Reward: 0.022234217502343112\n",
            "  Patch list: [0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1]\n",
            "  Selected Patches: 28\n",
            "  loss_reward: 1.1595705374209875\n",
            "  patches_reward: -0.5\n",
            "  Epsilon: 0.9554442691735238,   Reward: -0.08532024952212347\n",
            "  Patch list: [1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1]\n",
            "  Selected Patches: 30\n",
            "  loss_reward: 1.1212549054237542\n",
            "  patches_reward: -0.4166666666666667\n",
            "  Epsilon: 0.9549716651997764,   Reward: -0.027715293148015463\n",
            "  Patch list: [1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1]\n",
            "  Selected Patches: 34\n",
            "  loss_reward: 1.1450331550448203\n",
            "  patches_reward: -0.25\n",
            "  Epsilon: 0.9544992974689502,   Reward: 0.1156092834125497\n",
            "  Patch list: [0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1]\n",
            "  Selected Patches: 33\n",
            "  loss_reward: 1.1692921347899299\n",
            "  patches_reward: -0.2916666666666667\n",
            "  Epsilon: 0.9540271658629532,   Reward: 0.08823513107451372\n",
            "  Patch list: [1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1]\n",
            "  Selected Patches: 31\n",
            "  loss_reward: 1.1827741617767864\n",
            "  patches_reward: -0.375\n",
            "  Epsilon: 0.9535552702637528,   Reward: 0.023676765297500235\n",
            "  Patch list: [0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1]\n",
            "  Selected Patches: 34\n",
            "  loss_reward: 1.1564843560766256\n",
            "  patches_reward: -0.25\n",
            "  Epsilon: 0.9530836105533748,   Reward: 0.11881561970145518\n",
            "  Patch list: [0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1]\n",
            "  Selected Patches: 30\n",
            "  loss_reward: 1.1600194325767221\n",
            "  patches_reward: -0.4166666666666667\n",
            "  Epsilon: 0.9526121866139042,   Reward: -0.016861225545184433\n",
            "  Patch list: [0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0]\n",
            "  Selected Patches: 33\n",
            "  loss_reward: 1.1993660084649915\n",
            "  patches_reward: -0.2916666666666667\n",
            "  Epsilon: 0.9521409983274853,   Reward: 0.09665581570353102\n",
            "  Patch list: [1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1]\n",
            "  Selected Patches: 31\n",
            "  loss_reward: 1.1786570581301485\n",
            "  patches_reward: -0.375\n",
            "  Epsilon: 0.9516700455763208,   Reward: 0.02252397627644165\n",
            "  Patch list: [0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0]\n",
            "  Selected Patches: 28\n",
            "  loss_reward: 1.200282504861989\n",
            "  patches_reward: -0.5\n",
            "  Epsilon: 0.9511993282426727,   Reward: -0.07392089863864304\n",
            "  Patch list: [0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1]\n",
            "  Selected Patches: 31\n",
            "  loss_reward: 1.1826920406502155\n",
            "  patches_reward: -0.375\n",
            "  Epsilon: 0.9507288462088616,   Reward: 0.023653771382060373\n",
            "  Patch list: [1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0]\n",
            "  Selected Patches: 31\n",
            "  loss_reward: 1.1933270297951573\n",
            "  patches_reward: -0.375\n",
            "  Epsilon: 0.9502585993572668,   Reward: 0.026631568342644074\n",
            "  Patch list: [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1]\n",
            "  Selected Patches: 32\n",
            "  loss_reward: 1.1813349052955031\n",
            "  patches_reward: -0.3333333333333333\n",
            "  Epsilon: 0.9497885875703269,   Reward: 0.05744044014940758\n",
            "  Patch list: [0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0]\n",
            "  Selected Patches: 28\n",
            "  loss_reward: 1.1458306383427903\n",
            "  patches_reward: -0.5\n",
            "  Epsilon: 0.9493188107305387,   Reward: -0.08916742126401866\n",
            "  Patch list: [0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0]\n",
            "  Selected Patches: 33\n",
            "  loss_reward: 1.1862704342813797\n",
            "  patches_reward: -0.2916666666666667\n",
            "  Epsilon: 0.948849268720458,   Reward: 0.0929890549321197\n",
            "  Patch list: [1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0]\n",
            "  Selected Patches: 33\n",
            "  loss_reward: 1.2633294166696523\n",
            "  patches_reward: -0.2916666666666667\n",
            "  Epsilon: 0.9483799614226995,   Reward: 0.11456557000083598\n",
            "  Patch list: [0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0]\n",
            "  Selected Patches: 29\n",
            "  loss_reward: 1.2119034627767777\n",
            "  patches_reward: -0.4583333333333333\n",
            "  Epsilon: 0.9479108887199361,   Reward: -0.036500363755835485\n",
            "  Patch list: [0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0]\n",
            "  Selected Patches: 30\n",
            "  loss_reward: 1.180292578968307\n",
            "  patches_reward: -0.4166666666666667\n",
            "  Epsilon: 0.9474420504948999,   Reward: -0.011184744555540693\n",
            "  Patch list: [1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0]\n",
            "  Selected Patches: 33\n",
            "  loss_reward: 1.1720508611524918\n",
            "  patches_reward: -0.2916666666666667\n",
            "  Epsilon: 0.9469734466303812,   Reward: 0.08900757445603105\n",
            "  Patch list: [1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1]\n",
            "  Selected Patches: 33\n",
            "  loss_reward: 1.177045833577839\n",
            "  patches_reward: -0.2916666666666667\n",
            "  Epsilon: 0.946505077009229,   Reward: 0.09040616673512833\n",
            "  Patch list: [1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0]\n",
            "  Selected Patches: 37\n",
            "  loss_reward: 1.1576411540873526\n",
            "  patches_reward: -0.125\n",
            "  Epsilon: 0.9460369415143509,   Reward: 0.22163952314445878\n",
            "  Patch list: [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0]\n",
            "  Selected Patches: 28\n",
            "  loss_reward: 1.162872887280158\n",
            "  patches_reward: -0.5\n",
            "  Epsilon: 0.945569040028713,   Reward: -0.08439559156155574\n",
            "  Patch list: [1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]\n",
            "  Selected Patches: 37\n",
            "  loss_reward: 1.1759737125853822\n",
            "  patches_reward: -0.125\n",
            "  Epsilon: 0.9451013724353402,   Reward: 0.22677263952390708\n",
            "  Patch list: [0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0]\n",
            "  Selected Patches: 31\n",
            "  loss_reward: 1.1866147129657336\n",
            "  patches_reward: -0.375\n",
            "  Epsilon: 0.9446339386173151,   Reward: 0.024752119630405467\n",
            "  Patch list: [0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1]\n",
            "  Selected Patches: 35\n",
            "  loss_reward: 1.2085870518549082\n",
            "  patches_reward: -0.20833333333333334\n",
            "  Epsilon: 0.9441667384577798,   Reward: 0.167571041186041\n",
            "  Patch list: [1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1]\n",
            "  Selected Patches: 30\n",
            "  loss_reward: 1.21716585144116\n",
            "  patches_reward: -0.4166666666666667\n",
            "  Epsilon: 0.9436997718399338,   Reward: -0.0008602282631418046\n",
            "  Patch list: [0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0]\n",
            "  Selected Patches: 32\n",
            "  loss_reward: 1.2098043524176145\n",
            "  patches_reward: -0.3333333333333333\n",
            "  Epsilon: 0.9432330386470356,   Reward: 0.06541188534359876\n",
            "  Patch list: [0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0]\n",
            "  Selected Patches: 33\n",
            "  loss_reward: 1.1598723948138734\n",
            "  patches_reward: -0.2916666666666667\n",
            "  Epsilon: 0.942766538762402,   Reward: 0.08559760388121793\n",
            "  Patch list: [1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1]\n",
            "  Selected Patches: 28\n",
            "  loss_reward: 1.160417715372633\n",
            "  patches_reward: -0.5\n",
            "  Epsilon: 0.942300272069408,   Reward: -0.08508303969566272\n",
            "  Patch list: [0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0]\n",
            "  Selected Patches: 28\n",
            "  loss_reward: 1.198404991323804\n",
            "  patches_reward: -0.5\n",
            "  Epsilon: 0.9418342384514868,   Reward: -0.07444660242933482\n",
            "  Patch list: [1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1]\n",
            "  Selected Patches: 32\n",
            "  loss_reward: 1.1688439327349565\n",
            "  patches_reward: -0.3333333333333333\n",
            "  Epsilon: 0.9413684377921301,   Reward: 0.0539429678324545\n",
            "  Patch list: [1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0]\n",
            "  Selected Patches: 37\n",
            "  loss_reward: 1.1796181954067748\n",
            "  patches_reward: -0.125\n",
            "  Epsilon: 0.9409028699748877,   Reward: 0.22779309471389703\n",
            "  Patch list: [0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0]\n",
            "  Selected Patches: 28\n",
            "  loss_reward: 1.2010807844973292\n",
            "  patches_reward: -0.5\n",
            "  Epsilon: 0.9404375348833676,   Reward: -0.07369738034074774\n",
            "  Patch list: [0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0]\n",
            "  Selected Patches: 33\n",
            "  loss_reward: 1.1528902041062827\n",
            "  patches_reward: -0.2916666666666667\n",
            "  Epsilon: 0.9399724324012361,   Reward: 0.08364259048309255\n",
            "  Patch list: [0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1]\n",
            "  Selected Patches: 31\n",
            "  loss_reward: 1.1366576148663603\n",
            "  patches_reward: -0.375\n",
            "  Epsilon: 0.9395075624122174,   Reward: 0.01076413216258093\n",
            "  Patch list: [0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0]\n",
            "  Selected Patches: 35\n",
            "  loss_reward: 1.208147245315383\n",
            "  patches_reward: -0.20833333333333334\n",
            "  Epsilon: 0.9390429248000943,   Reward: 0.16744789535497395\n",
            "  Patch list: [1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0]\n",
            "  Selected Patches: 31\n",
            "  loss_reward: 1.2077748141347882\n",
            "  patches_reward: -0.375\n",
            "  Epsilon: 0.9385785194487073,   Reward: 0.03067694795774073\n",
            "  Patch list: [1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1]\n",
            "  Selected Patches: 35\n",
            "  loss_reward: 1.1251528620180082\n",
            "  patches_reward: -0.20833333333333334\n",
            "  Epsilon: 0.9381143462419549,   Reward: 0.14420946803170898\n",
            "  Patch list: [1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1]\n",
            "  Selected Patches: 35\n",
            "  loss_reward: 1.2106995434788552\n",
            "  patches_reward: -0.20833333333333334\n",
            "  Epsilon: 0.9376504050637938,   Reward: 0.16816253884074617\n",
            "  Patch list: [0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1]\n",
            "  Selected Patches: 31\n",
            "  loss_reward: 1.2046805208127174\n",
            "  patches_reward: -0.375\n",
            "  Epsilon: 0.937186695798239,   Reward: 0.029810545827560875\n",
            "  Patch list: [0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1]\n",
            "  Selected Patches: 32\n",
            "  loss_reward: 1.1902071955821896\n",
            "  patches_reward: -0.3333333333333333\n",
            "  Epsilon: 0.9367232183293628,   Reward: 0.05992468142967977\n",
            "  Patch list: [1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1]\n",
            "  Selected Patches: 32\n",
            "  loss_reward: 1.173920446762284\n",
            "  patches_reward: -0.3333333333333333\n",
            "  Epsilon: 0.9362599725412961,   Reward: 0.05536439176010621\n",
            "  Patch list: [0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1]\n",
            "  Selected Patches: 36\n",
            "  loss_reward: 1.181598265020619\n",
            "  patches_reward: -0.16666666666666666\n",
            "  Epsilon: 0.9357969583182274,   Reward: 0.1941808475391067\n",
            "  Patch list: [1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1]\n",
            "  Selected Patches: 34\n",
            "  loss_reward: 1.2398843626406582\n",
            "  patches_reward: -0.25\n",
            "  Epsilon: 0.9353341755444031,   Reward: 0.1421676215393843\n",
            "  Patch list: [1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1]\n",
            "  Selected Patches: 34\n",
            "  loss_reward: 1.2042802271655921\n",
            "  patches_reward: -0.25\n",
            "  Epsilon: 0.9348716241041275,   Reward: 0.13219846360636586\n",
            "  Patch list: [0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0]\n",
            "  Selected Patches: 34\n",
            "  loss_reward: 1.241332122363284\n",
            "  patches_reward: -0.25\n",
            "  Epsilon: 0.9344093038817626,   Reward: 0.14257299426171957\n",
            "  Patch list: [0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1]\n",
            "  Selected Patches: 32\n",
            "  loss_reward: 1.1957803522082704\n",
            "  patches_reward: -0.3333333333333333\n",
            "  Epsilon: 0.9339472147617286,   Reward: 0.061485165284982435\n",
            "  Patch list: [1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1]\n",
            "  Selected Patches: 34\n",
            "  loss_reward: 1.1629522790593911\n",
            "  patches_reward: -0.25\n",
            "  Epsilon: 0.9334853566285031,   Reward: 0.12062663813662958\n",
            "  Patch list: [0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1]\n",
            "  Selected Patches: 32\n",
            "  loss_reward: 1.2079016996033245\n",
            "  patches_reward: -0.3333333333333333\n",
            "  Epsilon: 0.9330237293666216,   Reward: 0.06487914255559757\n",
            "  Patch list: [1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0]\n",
            "  Selected Patches: 29\n",
            "  loss_reward: 1.1698711954607246\n",
            "  patches_reward: -0.4583333333333333\n",
            "  Epsilon: 0.9325623328606771,   Reward: -0.04826939860433038\n",
            "  Patch list: [1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0]\n",
            "  Selected Patches: 30\n",
            "  loss_reward: 1.1452970429145428\n",
            "  patches_reward: -0.4166666666666667\n",
            "  Epsilon: 0.9321011669953208,   Reward: -0.02098349465059468\n",
            "  Patch list: [0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0]\n",
            "  Selected Patches: 38\n",
            "  loss_reward: 1.2098003867331537\n",
            "  patches_reward: -0.08333333333333333\n",
            "  Epsilon: 0.9316402316552609,   Reward: 0.27041077495194976\n",
            "  Patch list: [0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0]\n",
            "  Selected Patches: 31\n",
            "  loss_reward: 1.2148834371781994\n",
            "  patches_reward: -0.375\n",
            "  Epsilon: 0.9311795267252638,   Reward: 0.03266736240989587\n",
            "  Patch list: [0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0]\n",
            "  Selected Patches: 28\n",
            "  loss_reward: 1.1989003010745236\n",
            "  patches_reward: -0.5\n",
            "  Epsilon: 0.9307190520901532,   Reward: -0.07430791569913331\n",
            "  Patch list: [0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1]\n",
            "  Selected Patches: 30\n",
            "  loss_reward: 1.2077641427406909\n",
            "  patches_reward: -0.4166666666666667\n",
            "  Epsilon: 0.9302588076348103,   Reward: -0.003492706699273207\n",
            "  Patch list: [0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1]\n",
            "  Selected Patches: 32\n",
            "  loss_reward: 1.1646608481397287\n",
            "  patches_reward: -0.3333333333333333\n",
            "  Epsilon: 0.9297987932441742,   Reward: 0.05277170414579074\n",
            "  Patch list: [0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0]\n",
            "  Selected Patches: 28\n",
            "  loss_reward: 1.1972340720934487\n",
            "  patches_reward: -0.5\n",
            "  Epsilon: 0.9293390088032413,   Reward: -0.0747744598138343\n",
            "  Patch list: [1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1]\n",
            "  Selected Patches: 35\n",
            "  loss_reward: 1.1650560728251196\n",
            "  patches_reward: -0.20833333333333334\n",
            "  Epsilon: 0.9288794541970652,   Reward: 0.1553823670577002\n",
            "  Patch list: [0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0]\n",
            "  Selected Patches: 33\n",
            "  loss_reward: 1.2217614931418088\n",
            "  patches_reward: -0.2916666666666667\n",
            "  Epsilon: 0.9284201293107576,   Reward: 0.10292655141303983\n",
            "  Patch list: [0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0]\n",
            "  Selected Patches: 32\n",
            "  loss_reward: 1.3187101255485072\n",
            "  patches_reward: -0.3333333333333333\n",
            "  Epsilon: 0.927961034029487,   Reward: 0.0959055018202487\n",
            "  Patch list: [1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1]\n",
            "  Selected Patches: 32\n",
            "  loss_reward: 1.1985718222959485\n",
            "  patches_reward: -0.3333333333333333\n",
            "  Epsilon: 0.9275021682384798,   Reward: 0.062266776909532306\n",
            "  Patch list: [0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1]\n",
            "  Selected Patches: 31\n",
            "  loss_reward: 1.2218046357323578\n",
            "  patches_reward: -0.375\n",
            "  Epsilon: 0.9270435318230192,   Reward: 0.03460529800506024\n",
            "  Patch list: [0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1]\n",
            "  Selected Patches: 33\n",
            "  loss_reward: 1.2330763345431544\n",
            "  patches_reward: -0.2916666666666667\n",
            "  Epsilon: 0.9265851246684466,   Reward: 0.1060947070054166\n",
            "  Patch list: [0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0]\n",
            "  Selected Patches: 26\n",
            "  loss_reward: 1.2022980173210227\n",
            "  patches_reward: -0.5833333333333334\n",
            "  Epsilon: 0.9261269466601597,   Reward: -0.14168988848344694\n",
            "  Patch list: [0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0]\n",
            "  Selected Patches: 27\n",
            "  loss_reward: 1.2098782510939787\n",
            "  patches_reward: -0.5416666666666666\n",
            "  Epsilon: 0.9256689976836144,   Reward: -0.10540075636035251\n",
            "\n",
            "Inizio Testing\n",
            "\n",
            "\n",
            "Average test loss: 4.2707  Accuracy:  969/ 9500 (10.20%)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch time: 88.07994604110718\n",
            "########################################\n",
            "########################################\n",
            "Episode End\n",
            "########################################\n",
            "########################################\n",
            "Epoch: 3/20\n",
            "  Patch list: [1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1]\n",
            "  Selected Patches: 34\n",
            "  loss_reward: 1.2282337290909409\n",
            "  patches_reward: -0.25\n",
            "  Epsilon: 0.9251197610724647,   Reward: 0.18553479330910114\n",
            "  Patch list: [1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1]\n",
            "  Selected Patches: 36\n",
            "  loss_reward: 1.1970704605674851\n",
            "  patches_reward: -0.16666666666666666\n",
            "  Epsilon: 0.924662315562836,   Reward: 0.24472921404826198\n",
            "  Patch list: [0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0]\n",
            "  Selected Patches: 33\n",
            "  loss_reward: 1.2568039540659814\n",
            "  patches_reward: -0.2916666666666667\n",
            "  Epsilon: 0.924205098718791,   Reward: 0.1600939319677808\n",
            "  Patch list: [0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1]\n",
            "  Selected Patches: 30\n",
            "  loss_reward: 1.2294353845631112\n",
            "  patches_reward: -0.4166666666666667\n",
            "  Epsilon: 0.9237481104260252,   Reward: 0.04758598972686234\n",
            "  Patch list: [1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0]\n",
            "  Selected Patches: 30\n",
            "  loss_reward: 1.1962909432645745\n",
            "  patches_reward: -0.4166666666666667\n",
            "  Epsilon: 0.923291350570292,   Reward: 0.03697976851133061\n",
            "  Patch list: [1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0]\n",
            "  Selected Patches: 37\n",
            "  loss_reward: 1.1981303273712585\n",
            "  patches_reward: -0.125\n",
            "  Epsilon: 0.9228348190374012,   Reward: 0.2796517047588028\n",
            "  Patch list: [1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1]\n",
            "  Selected Patches: 33\n",
            "  loss_reward: 1.2185679863018613\n",
            "  patches_reward: -0.2916666666666667\n",
            "  Epsilon: 0.9223785157132198,   Reward: 0.14785842228326232\n",
            "  Patch list: [0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1]\n",
            "  Selected Patches: 31\n",
            "  loss_reward: 1.2292130423154632\n",
            "  patches_reward: -0.375\n",
            "  Epsilon: 0.9219224404836722,   Reward: 0.08209817354094834\n",
            "  Patch list: [1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0]\n",
            "  Selected Patches: 33\n",
            "  loss_reward: 1.276935571446299\n",
            "  patches_reward: -0.2916666666666667\n",
            "  Epsilon: 0.9214665932347395,   Reward: 0.16653604952948245\n",
            "  Patch list: [0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1]\n",
            "  Selected Patches: 33\n",
            "  loss_reward: 1.2230003574399875\n",
            "  patches_reward: -0.2916666666666667\n",
            "  Epsilon: 0.9210109738524597,   Reward: 0.1492767810474627\n",
            "  Patch list: [0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1]\n",
            "  Selected Patches: 33\n",
            "  loss_reward: 1.2149007667091853\n",
            "  patches_reward: -0.2916666666666667\n",
            "  Epsilon: 0.9205555822229282,   Reward: 0.14668491201360603\n",
            "  Patch list: [1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0]\n",
            "  Selected Patches: 35\n",
            "  loss_reward: 1.2188484789974403\n",
            "  patches_reward: -0.20833333333333334\n",
            "  Epsilon: 0.9201004182322969,   Reward: 0.2171148466125143\n",
            "  Patch list: [1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1]\n",
            "  Selected Patches: 32\n",
            "  loss_reward: 1.1824033175190456\n",
            "  patches_reward: -0.3333333333333333\n",
            "  Epsilon: 0.9196454817667751,   Reward: 0.10170239493942806\n",
            "  Patch list: [1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1]\n",
            "  Selected Patches: 32\n",
            "  loss_reward: 1.2461801640113852\n",
            "  patches_reward: -0.3333333333333333\n",
            "  Epsilon: 0.9191907727126283,   Reward: 0.12211098581697671\n",
            "  Patch list: [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1]\n",
            "  Selected Patches: 35\n",
            "  loss_reward: 1.2110625212400665\n",
            "  patches_reward: -0.20833333333333334\n",
            "  Epsilon: 0.9187362909561795,   Reward: 0.21462334013015472\n",
            "  Patch list: [1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1]\n",
            "  Selected Patches: 31\n",
            "  loss_reward: 1.3250363311973914\n",
            "  patches_reward: -0.375\n",
            "  Epsilon: 0.9182820363838081,   Reward: 0.11276162598316536\n",
            "  Patch list: [0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1]\n",
            "  Selected Patches: 33\n",
            "  loss_reward: 1.1974556143328043\n",
            "  patches_reward: -0.2916666666666667\n",
            "  Epsilon: 0.9178280088819505,   Reward: 0.14110246325316414\n",
            "  Patch list: [0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0]\n",
            "  Selected Patches: 33\n",
            "  loss_reward: 1.2192292487724734\n",
            "  patches_reward: -0.2916666666666667\n",
            "  Epsilon: 0.9173742083370999,   Reward: 0.1480700262738582\n",
            "  Patch list: [1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1]\n",
            "  Selected Patches: 33\n",
            "  loss_reward: 1.290293897978431\n",
            "  patches_reward: -0.2916666666666667\n",
            "  Epsilon: 0.9169206346358061,   Reward: 0.1708107140197647\n",
            "  Patch list: [1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1]\n",
            "  Selected Patches: 35\n",
            "  loss_reward: 1.2466191879926258\n",
            "  patches_reward: -0.20833333333333334\n",
            "  Epsilon: 0.9164672876646758,   Reward: 0.22600147349097366\n",
            "  Patch list: [1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0]\n",
            "  Selected Patches: 34\n",
            "  loss_reward: 1.248980958374596\n",
            "  patches_reward: -0.25\n",
            "  Epsilon: 0.916014167310372,   Reward: 0.19217390667987086\n",
            "  Patch list: [1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1]\n",
            "  Selected Patches: 31\n",
            "  loss_reward: 1.1890086913940325\n",
            "  patches_reward: -0.375\n",
            "  Epsilon: 0.9155612734596148,   Reward: 0.0692327812460905\n",
            "  Patch list: [1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1]\n",
            "  Selected Patches: 28\n",
            "  loss_reward: 1.2161459197165645\n",
            "  patches_reward: -0.5\n",
            "  Epsilon: 0.9151086059991806,   Reward: -0.02583330569069925\n",
            "  Patch list: [0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1]\n",
            "  Selected Patches: 34\n",
            "  loss_reward: 1.203655488722949\n",
            "  patches_reward: -0.25\n",
            "  Epsilon: 0.9146561648159027,   Reward: 0.17766975639134372\n",
            "  Patch list: [1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0]\n",
            "  Selected Patches: 32\n",
            "  loss_reward: 1.1840837009215344\n",
            "  patches_reward: -0.3333333333333333\n",
            "  Epsilon: 0.9142039497966707,   Reward: 0.10224011762822444\n",
            "  Patch list: [0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0]\n",
            "  Selected Patches: 32\n",
            "  loss_reward: 1.248862762985707\n",
            "  patches_reward: -0.3333333333333333\n",
            "  Epsilon: 0.9137519608284309,   Reward: 0.12296941748875967\n",
            "  Patch list: [0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1]\n",
            "  Selected Patches: 29\n",
            "  loss_reward: 1.2485996860048891\n",
            "  patches_reward: -0.4583333333333333\n",
            "  Epsilon: 0.9133001977981859,   Reward: 0.019135232854897988\n",
            "  Patch list: [1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1]\n",
            "  Selected Patches: 32\n",
            "  loss_reward: 1.193505314918043\n",
            "  patches_reward: -0.3333333333333333\n",
            "  Epsilon: 0.9128486605929952,   Reward: 0.10525503410710724\n",
            "  Patch list: [0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1]\n",
            "  Selected Patches: 39\n",
            "  loss_reward: 1.3154840064879856\n",
            "  patches_reward: -0.041666666666666664\n",
            "  Epsilon: 0.9123973490999743,   Reward: 0.3863715487428221\n",
            "  Patch list: [1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1]\n",
            "  Selected Patches: 33\n",
            "  loss_reward: 1.174429727264878\n",
            "  patches_reward: -0.2916666666666667\n",
            "  Epsilon: 0.9119462632062955,   Reward: 0.1337341793914277\n",
            "  Patch list: [1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0]\n",
            "  Selected Patches: 32\n",
            "  loss_reward: 1.2676806829811937\n",
            "  patches_reward: -0.3333333333333333\n",
            "  Epsilon: 0.9114954027991868,   Reward: 0.12899115188731547\n",
            "  Patch list: [1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1]\n",
            "  Selected Patches: 33\n",
            "  loss_reward: 1.2951225121106118\n",
            "  patches_reward: -0.2916666666666667\n",
            "  Epsilon: 0.9110447677659339,   Reward: 0.1723558705420625\n",
            "  Patch list: [0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0]\n",
            "  Selected Patches: 30\n",
            "  loss_reward: 1.259489697452423\n",
            "  patches_reward: -0.4166666666666667\n",
            "  Epsilon: 0.9105943579938774,   Reward: 0.05720336985144209\n",
            "  Patch list: [0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0]\n",
            "  Selected Patches: 28\n",
            "  loss_reward: 1.2549119924416152\n",
            "  patches_reward: -0.5\n",
            "  Epsilon: 0.9101441733704152,   Reward: -0.013428162418683054\n",
            "  Patch list: [0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1]\n",
            "  Selected Patches: 33\n",
            "  loss_reward: 1.1903499960006847\n",
            "  patches_reward: -0.2916666666666667\n",
            "  Epsilon: 0.9096942137830011,   Reward: 0.13882866538688585\n",
            "  Patch list: [0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1]\n",
            "  Selected Patches: 32\n",
            "  loss_reward: 1.218342049518023\n",
            "  patches_reward: -0.3333333333333333\n",
            "  Epsilon: 0.9092444791191451,   Reward: 0.11320278917910082\n",
            "  Patch list: [1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\n",
            "  Selected Patches: 32\n",
            "  loss_reward: 1.2554490023272888\n",
            "  patches_reward: -0.3333333333333333\n",
            "  Epsilon: 0.9087949692664135,   Reward: 0.12507701407806587\n",
            "  Patch list: [1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1]\n",
            "  Selected Patches: 33\n",
            "  loss_reward: 1.2286543343490235\n",
            "  patches_reward: -0.2916666666666667\n",
            "  Epsilon: 0.9083456841124288,   Reward: 0.15108605365835423\n",
            "  Patch list: [0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0]\n",
            "  Selected Patches: 32\n",
            "  loss_reward: 1.2872380769909544\n",
            "  patches_reward: -0.3333333333333333\n",
            "  Epsilon: 0.9078966235448699,   Reward: 0.13524951797043888\n",
            "  Patch list: [1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1]\n",
            "  Selected Patches: 33\n",
            "  loss_reward: 1.2601531033410562\n",
            "  patches_reward: -0.2916666666666667\n",
            "  Epsilon: 0.9074477874514715,   Reward: 0.16116565973580474\n",
            "  Patch list: [1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0]\n",
            "  Selected Patches: 32\n",
            "  loss_reward: 1.2611123197113332\n",
            "  patches_reward: -0.3333333333333333\n",
            "  Epsilon: 0.9069991757200248,   Reward: 0.1268892756409601\n",
            "  Patch list: [0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0]\n",
            "  Selected Patches: 34\n",
            "  loss_reward: 1.231291780171133\n",
            "  patches_reward: -0.25\n",
            "  Epsilon: 0.9065507882383765,   Reward: 0.18651336965476265\n",
            "  Patch list: [1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1]\n",
            "  Selected Patches: 28\n",
            "  loss_reward: 1.1670955199718518\n",
            "  patches_reward: -0.5\n",
            "  Epsilon: 0.9061026248944302,   Reward: -0.04152943360900735\n",
            "  Patch list: [1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0]\n",
            "  Selected Patches: 28\n",
            "  loss_reward: 1.2531753394008291\n",
            "  patches_reward: -0.5\n",
            "  Epsilon: 0.9056546855761446,   Reward: -0.01398389139173456\n",
            "  Patch list: [0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0]\n",
            "  Selected Patches: 35\n",
            "  loss_reward: 1.2839716769333531\n",
            "  patches_reward: -0.20833333333333334\n",
            "  Epsilon: 0.9052069701715351,   Reward: 0.23795426995200641\n",
            "  Patch list: [1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "  Selected Patches: 30\n",
            "  loss_reward: 1.2397398417897516\n",
            "  patches_reward: -0.4166666666666667\n",
            "  Epsilon: 0.9047594785686727,   Reward: 0.050883416039387286\n",
            "  Patch list: [0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1]\n",
            "  Selected Patches: 32\n",
            "  loss_reward: 1.2685566285081324\n",
            "  patches_reward: -0.3333333333333333\n",
            "  Epsilon: 0.9043122106556847,   Reward: 0.12927145445593585\n",
            "  Patch list: [0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1]\n",
            "  Selected Patches: 30\n",
            "  loss_reward: 1.2106604909822214\n",
            "  patches_reward: -0.4166666666666667\n",
            "  Epsilon: 0.903865166320754,   Reward: 0.04157802378097758\n",
            "  Patch list: [0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1]\n",
            "  Selected Patches: 33\n",
            "  loss_reward: 1.2566302178473803\n",
            "  patches_reward: -0.2916666666666667\n",
            "  Epsilon: 0.9034183454521195,   Reward: 0.1600383363778284\n",
            "  Patch list: [1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0]\n",
            "  Selected Patches: 32\n",
            "  loss_reward: 1.3027278789872558\n",
            "  patches_reward: -0.3333333333333333\n",
            "  Epsilon: 0.9029717479380761,   Reward: 0.14020625460925534\n",
            "  Patch list: [1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0]\n",
            "  Selected Patches: 30\n",
            "  loss_reward: 1.2181920523287375\n",
            "  patches_reward: -0.4166666666666667\n",
            "  Epsilon: 0.9025253736669744,   Reward: 0.043988123411862756\n",
            "  Patch list: [1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1]\n",
            "  Selected Patches: 35\n",
            "  loss_reward: 1.279188899859305\n",
            "  patches_reward: -0.20833333333333334\n",
            "  Epsilon: 0.9020792225272206,   Reward: 0.23642378128831104\n",
            "  Patch list: [0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0]\n",
            "  Selected Patches: 28\n",
            "  loss_reward: 1.2537507554164933\n",
            "  patches_reward: -0.5\n",
            "  Epsilon: 0.9016332944072771,   Reward: -0.013799758266722029\n",
            "  Patch list: [0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0]\n",
            "  Selected Patches: 29\n",
            "  loss_reward: 1.2276941517332685\n",
            "  patches_reward: -0.4583333333333333\n",
            "  Epsilon: 0.901187589195662,   Reward: 0.012445461887979348\n",
            "  Patch list: [1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1]\n",
            "  Selected Patches: 35\n",
            "  loss_reward: 1.2661851827921453\n",
            "  patches_reward: -0.20833333333333334\n",
            "  Epsilon: 0.9007421067809487,   Reward: 0.2322625918268199\n",
            "  Patch list: [0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0]\n",
            "  Selected Patches: 28\n",
            "  loss_reward: 1.248640098013311\n",
            "  patches_reward: -0.5\n",
            "  Epsilon: 0.9002968470517667,   Reward: -0.015435168635740404\n",
            "  Patch list: [0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0]\n",
            "  Selected Patches: 29\n",
            "  loss_reward: 1.2603140429659732\n",
            "  patches_reward: -0.4583333333333333\n",
            "  Epsilon: 0.8998518098968011,   Reward: 0.022883827082444852\n",
            "  Patch list: [0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1]\n",
            "  Selected Patches: 32\n",
            "  loss_reward: 1.2704041269216582\n",
            "  patches_reward: -0.3333333333333333\n",
            "  Epsilon: 0.8994069952047927,   Reward: 0.12986265394826407\n",
            "  Patch list: [1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1]\n",
            "  Selected Patches: 31\n",
            "  loss_reward: 1.178289668459405\n",
            "  patches_reward: -0.375\n",
            "  Epsilon: 0.8989624028645378,   Reward: 0.06580269390700971\n",
            "  Patch list: [1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1]\n",
            "  Selected Patches: 34\n",
            "  loss_reward: 1.2462009226399067\n",
            "  patches_reward: -0.25\n",
            "  Epsilon: 0.8985180327648881,   Reward: 0.19128429524477022\n",
            "  Patch list: [1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0]\n",
            "  Selected Patches: 32\n",
            "  loss_reward: 1.1908263730481956\n",
            "  patches_reward: -0.3333333333333333\n",
            "  Epsilon: 0.8980738847947514,   Reward: 0.10439777270875605\n",
            "  Patch list: [0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1]\n",
            "  Selected Patches: 35\n",
            "  loss_reward: 1.2415466196009657\n",
            "  patches_reward: -0.20833333333333334\n",
            "  Epsilon: 0.8976299588430903,   Reward: 0.22437825160564245\n",
            "  Patch list: [0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0]\n",
            "  Selected Patches: 28\n",
            "  loss_reward: 1.211565699849169\n",
            "  patches_reward: -0.5\n",
            "  Epsilon: 0.8971862547989237,   Reward: -0.02729897604826581\n",
            "  Patch list: [0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0]\n",
            "  Selected Patches: 27\n",
            "  loss_reward: 1.2626583433307637\n",
            "  patches_reward: -0.5416666666666666\n",
            "  Epsilon: 0.8967427725513253,   Reward: -0.045532663467488854\n",
            "  Patch list: [0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1]\n",
            "  Selected Patches: 32\n",
            "  loss_reward: 1.2734936672957753\n",
            "  patches_reward: -0.3333333333333333\n",
            "  Epsilon: 0.8962995119894246,   Reward: 0.13085130686798158\n",
            "  Patch list: [1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0]\n",
            "  Selected Patches: 33\n",
            "  loss_reward: 1.2744778561896921\n",
            "  patches_reward: -0.2916666666666667\n",
            "  Epsilon: 0.8958564730024068,   Reward: 0.1657495806473682\n",
            "  Patch list: [1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1]\n",
            "  Selected Patches: 31\n",
            "  loss_reward: 1.3003055653193287\n",
            "  patches_reward: -0.375\n",
            "  Epsilon: 0.8954136554795116,   Reward: 0.10484778090218533\n",
            "  Patch list: [1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0]\n",
            "  Selected Patches: 35\n",
            "  loss_reward: 1.2996150858007824\n",
            "  patches_reward: -0.20833333333333334\n",
            "  Epsilon: 0.894971059310035,   Reward: 0.24296016078958382\n",
            "  Patch list: [0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1]\n",
            "  Selected Patches: 29\n",
            "  loss_reward: 1.1593122916954388\n",
            "  patches_reward: -0.4583333333333333\n",
            "  Epsilon: 0.8945286843833278,   Reward: -0.009436733324126145\n",
            "  Patch list: [0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1]\n",
            "  Selected Patches: 33\n",
            "  loss_reward: 1.2423406673675683\n",
            "  patches_reward: -0.2916666666666667\n",
            "  Epsilon: 0.8940865305887963,   Reward: 0.1554656802242886\n",
            "  Patch list: [0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0]\n",
            "  Selected Patches: 30\n",
            "  loss_reward: 1.2425778247528878\n",
            "  patches_reward: -0.4166666666666667\n",
            "  Epsilon: 0.893644597815902,   Reward: 0.051791570587590874\n",
            "  Patch list: [0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0]\n",
            "  Selected Patches: 33\n",
            "  loss_reward: 1.272667941156457\n",
            "  patches_reward: -0.2916666666666667\n",
            "  Epsilon: 0.8932028859541619,   Reward: 0.16517040783673295\n",
            "  Patch list: [1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0]\n",
            "  Selected Patches: 37\n",
            "  loss_reward: 1.215157701670973\n",
            "  patches_reward: -0.125\n",
            "  Epsilon: 0.8927613948931477,   Reward: 0.2851004645347114\n",
            "  Patch list: [1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0]\n",
            "  Selected Patches: 36\n",
            "  loss_reward: 1.248543930176307\n",
            "  patches_reward: -0.16666666666666666\n",
            "  Epsilon: 0.892320124522487,   Reward: 0.261200724323085\n"
          ]
        }
      ],
      "source": [
        "initial = time.time()\n",
        "step_reward, selected_patch = model.train_test(models_save_path, dataset_name)\n",
        "print(f'Total Time: {time.time()-initial}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nFrUrs52AXj2"
      },
      "source": [
        "<h3> Train and Validation Informations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UgD0RgDZPBIV"
      },
      "outputs": [],
      "source": [
        "results_train = model.train_info()\n",
        "train_loss = results_train['train_loss']\n",
        "train_time = results_train['train_time']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PkaW5esyAWin"
      },
      "outputs": [],
      "source": [
        "results_validation = model.validation_info()\n",
        "validation_loss = results_validation['validation_loss']\n",
        "validation_acc = results_validation['validation_acc']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hs_EI4dyQVbn"
      },
      "source": [
        "<h3> Saving Results in CSV format\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v2_mduauQVbn"
      },
      "outputs": [],
      "source": [
        "save_name=\"halfres_pretrained-frozen-cnn_default-configs_8patch_rebalanceR\"\n",
        "\n",
        "df = pd.DataFrame(results_train)\n",
        "\n",
        "df.to_csv(f'{results_save_path_agent}{dataset_name}_train_lowres_dr_e100_{save_name}.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UaCe4CUbAqs0"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(results_validation)\n",
        "\n",
        "df.to_csv(f'{results_save_path_agent}{dataset_name}_validation_lowres_dr_e100_{save_name}.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRuW0NCbi57h"
      },
      "source": [
        "### Plot of Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PyzpwMapQVbo"
      },
      "source": [
        "<h3> Train Loss during iterations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9wQo9_t_QVbo"
      },
      "outputs": [],
      "source": [
        "model_name = \"half-Res Pretrained frozen CNN (Default Configs), 8x8 patches, ReBalance Reward\"\n",
        "\n",
        "plt.plot(range(len(train_loss)), train_loss, label='Train Loss')\n",
        "\n",
        "plt.legend()\n",
        "plt.title('Loss over time: {}'.format(model_name))\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Loss')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LauYoQB1i_Rn"
      },
      "source": [
        "<h3> Validation Loss during epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C2SINTgRBXoP"
      },
      "outputs": [],
      "source": [
        "plt.plot(range(len(validation_loss)), validation_loss, label='Validation Loss')\n",
        "\n",
        "plt.legend()\n",
        "plt.title('Loss over time: {}'.format(model_name))\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XidgR27RQVbo"
      },
      "source": [
        "<h3> Validation Accuracy during epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SU4iIA1hQVbp"
      },
      "outputs": [],
      "source": [
        "x = range(len(validation_acc))\n",
        "y = validation_acc\n",
        "\n",
        "plt.plot(x, y, label='Validation Accuracy')\n",
        "\n",
        "plt.legend()\n",
        "plt.title('Accuracy over time: {}'.format(model_name))\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ISnRZwlzjtmK"
      },
      "outputs": [],
      "source": [
        "validation_acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJ6icTgAp8Vb"
      },
      "source": [
        "## Evaluation for different Heuristics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xmu5b4veuD5r"
      },
      "outputs": [],
      "source": [
        "def evaluate_agent(agent, data_load, device, mode = False):\n",
        "\n",
        "    agent.eval()\n",
        "\n",
        "    elements = 0\n",
        "    csamp = 0\n",
        "    tloss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, target in data_load:\n",
        "\n",
        "            elements += len(data)\n",
        "            data = data.to(device)\n",
        "            target = target.to(device)\n",
        "\n",
        "            state = env.get_state(data)\n",
        "\n",
        "            if mode == \"agent\":\n",
        "              action = model.agent.select_action(state)\n",
        "            elif mode == \"random\":\n",
        "              action = model.env.action_space.sample()\n",
        "            else:\n",
        "              action = torch.tensor([1 for i in range(len(model.env.action_space.sample()))], dtype = torch.float)\n",
        "\n",
        "            ViTnet.set_patches(action)\n",
        "\n",
        "            output = functional.log_softmax(agent(data), dim=1)\n",
        "            loss = functional.nll_loss(output, target, reduction='sum')\n",
        "            _, pred = torch.max(output, dim=1)\n",
        "\n",
        "            tloss += loss.item()\n",
        "            csamp += pred.eq(target).sum()\n",
        "\n",
        "    loss_val = tloss / elements\n",
        "    acc_val = (100.0 * csamp / elements).cpu()\n",
        "\n",
        "    print('\\nAverage validation loss: ' + '{:.4f}'.format(loss_val) +\n",
        "          '  Accuracy:' + '{:5}'.format(csamp) + '/' +\n",
        "          '{:5}'.format(elements) + ' (' +\n",
        "          '{:4.2f}'.format(acc_val) + '%)\\n')\n",
        "\n",
        "    return loss_val, acc_val\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akTharX5RaL8"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mrDXnFLRldw"
      },
      "source": [
        "<h3> All Patches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qk6xh-DBwAK6"
      },
      "outputs": [],
      "source": [
        "evaluate_agent(ViTnet, train_loader, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usZfBwXwRqx-"
      },
      "source": [
        "<h3> Patches Selected By agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jKZ0-kJENBnT"
      },
      "outputs": [],
      "source": [
        "# time-dependent reward component\n",
        "evaluate_agent(ViTnet, train_loader, device, mode = \"agent\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g46_tdT9Rtg3"
      },
      "source": [
        "<h3> Random Patches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i-BY6MmuwN8a"
      },
      "outputs": [],
      "source": [
        "evaluate_agent(ViTnet, train_loader, device, mode = \"random\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VY2VipXRejU"
      },
      "source": [
        "### Validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uygahgWaRx2P"
      },
      "source": [
        "<h3> All Patches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ROoB1IPaNGAB"
      },
      "outputs": [],
      "source": [
        "evaluate_agent(ViTnet, test_loader, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPKqXZkxRwNO"
      },
      "source": [
        "<h3> Patches Selected By agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wmkSeWCPNJZg"
      },
      "outputs": [],
      "source": [
        "evaluate_agent(ViTnet, test_loader, device, mode = \"agent\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feUitG6eRzss"
      },
      "source": [
        "<h3> Random Patches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XcSSTkULckjY"
      },
      "outputs": [],
      "source": [
        "evaluate_agent(ViTnet, test_loader, device, mode = \"random\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "weElHDyUNTOh"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
